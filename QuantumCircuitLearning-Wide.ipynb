{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wide Quantum Circuit Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import pennylane.optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from MNISTData import MNISTData\n",
    "from AutoEncoder import AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODING_SIZE = 10\n",
    "NUM_QUBITS =4\n",
    "NUM_CLASSES= 10\n",
    "# NUM_LAYERS specifies how many times the circuit is run over the qubit wires.\n",
    "# Should increase runtime by a factor of NUM_LAYERS.\n",
    "NUM_LAYERS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dev = qml.device(\"forest.qvm\", device=\"{}q-pyqvm\".format(NUM_QUBITS), shots=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pennylane.ops import RX, RY, CNOT\n",
    "\n",
    "# x will be a length ENCODING_SIZE vector that represents\n",
    "# the encoding of a MNIST image\n",
    "# thetas is of size 2 * NUM_QUBITS\n",
    "@qml.qnode(dev)\n",
    "def circuit(x, thetas):\n",
    "    for i in range(ENCODING_SIZE):\n",
    "        RX(x[i], wires=i)\n",
    "    for j in range(NUM_LAYERS):\n",
    "        for i in range(NUM_QUBITS - 1):\n",
    "            CNOT(wires=[i, i+1])\n",
    "        for i in range(NUM_QUBITS):\n",
    "            RX(thetas[j][i], wires=i)\n",
    "        for i in range(NUM_QUBITS, 2 * NUM_QUBITS):\n",
    "            RY(thetas[j][i], wires=(i - NUM_QUBITS))\n",
    "    return tuple(qml.expval.PauliZ(wires=i) for i in range(NUM_QUBITS))\n",
    "\n",
    "\n",
    "#params: x - input x\n",
    "#        mask - mapping from range(ENCODING SIZE) to range(4)\n",
    "#        thetas - learned parameters\n",
    "#NOTE: Written for NUM_QUBITS = 4\n",
    "@qml.qnode(dev)\n",
    "def circuit_tighten(x, mask, thetas):\n",
    "    for i in range(ENCODING_SIZE):\n",
    "            if i // NUM_QUBITS % 2 == 0: \n",
    "                RX(x[i], wires=i//NUM_QUBITS)\n",
    "            else:\n",
    "                RY(x[i], wires=i//NUM_QUBITS)\n",
    "    for j in range(NUM_LAYERS):\n",
    "        CNOT(wires=[0, 1])\n",
    "        CNOT(wires=[1, 3])\n",
    "        CNOT(wires=[0, 2])\n",
    "        for i in range(NUM_QUBITS):\n",
    "            RX(thetas[j][i], wires=i)\n",
    "        for i in range(NUM_QUBITS, 2 * NUM_QUBITS):\n",
    "            RY(thetas[j][i], wires=(i - NUM_QUBITS))\n",
    "    return [qml.expval.PauliZ(wires=i) for i in range(NUM_QUBITS)]\n",
    "\n",
    "def get_mask():\n",
    "    sub_masks = []\n",
    "    for i in range(ENCODING_SIZE//NUM_QUBITS + 1):\n",
    "        sub_masks.append(np.random.permutation(NUM_QUBITS))\n",
    "    res = np.concatenate(sub_masks).flatten()\n",
    "    return res.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5425\n"
     ]
    }
   ],
   "source": [
    "# example input\n",
    "MASK = get_mask()\n",
    "print(np.mean(circuit_tighten([np.pi/5]*(ENCODING_SIZE), MASK, [[np.pi]*(2 * NUM_QUBITS)]*NUM_LAYERS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: EDITED COST FUNCTION to use bias, and to prevent bias from gaming\n",
    "#       the cost function.\n",
    "def cost(X, actual_labels, thetas, bias):\n",
    "    b = X.shape[0]\n",
    "    yhats = []\n",
    "    for i in range(b):\n",
    "        scores = []\n",
    "        for j in range(NUM_CLASSES):\n",
    "            scores.append(np.mean(circuit_tighten(X[i], MASK, thetas[j]) + bias[j]))\n",
    "        yhats.append(scores)\n",
    "    st = np.stack(yhats)\n",
    "    actual_class_vals = st[range(b), actual_labels]\n",
    "    shifted = st - np.max(st, axis=1)[:, np.newaxis]\n",
    "    the_sum = np.log(np.sum(np.exp(shifted), axis=1)) \n",
    "    # Return loss + regularization term on bias\n",
    "    return np.mean(-actual_class_vals + the_sum + np.max(st, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have to get our (encoded) images so that we may actually start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = MNISTData(batch_size=16)\n",
    "train_loader = data.get_train_loader()\n",
    "test_loader = data.get_test_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_from_stem = \"./autoencoder_models/1558731906/\"\n",
    "load_model_from = os.path.join(load_from_stem, \"ae.pt\")\n",
    "load_layers_from = os.path.join(load_from_stem, \"layer_sizes.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(load_layers_from, 'rb') as f:\n",
    "    layer_sizes = pickle.load(f)\n",
    "layer_sizes = layer_sizes[1:]\n",
    "ae = AutoEncoder(layer_sizes)\n",
    "ae.load_state_dict(torch.load(load_model_from))\n",
    "encoder = ae.encoder\n",
    "for child in encoder.children():\n",
    "    for param in child.parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                  [-1, 256]         200,960\n",
      "              ReLU-2                  [-1, 256]               0\n",
      "            Linear-3                   [-1, 64]          16,448\n",
      "              ReLU-4                   [-1, 64]               0\n",
      "            Linear-5                   [-1, 10]             650\n",
      "              ReLU-6                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 218,058\n",
      "Trainable params: 0\n",
      "Non-trainable params: 218,058\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.83\n",
      "Estimated Total Size (MB): 0.84\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(encoder, input_size=(28 * 28,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-6.78585071e-02  1.78117656e-02 -7.20868112e-03  8.46867869e-02\n",
      "   -3.18339767e-02  6.24732989e-03 -2.42707438e-02 -4.46353180e-02]\n",
      "  [ 2.62399358e-01 -9.47407240e-02  3.94976471e-02 -9.78486023e-02\n",
      "    6.62962250e-02  2.64429538e-02  7.87796514e-02 -3.93971494e-02]\n",
      "  [-4.20314937e-02 -2.17390872e-02  1.01371850e-01  3.44254246e-02\n",
      "    1.00162936e-01  1.49950090e-01 -1.65052160e-01  6.41760634e-03]\n",
      "  [-3.02023615e-01 -5.90971181e-02 -1.06066674e-01  5.24614749e-02\n",
      "    8.99245202e-02 -4.93045484e-02  4.10534633e-02  2.07723163e-02]\n",
      "  [-2.05823476e-01  6.44673815e-02  5.28275671e-02 -1.16312905e-01\n",
      "   -8.26997459e-02  5.24263870e-02  1.61978660e-01 -7.13220520e-02]\n",
      "  [-4.55717809e-02 -1.16163263e-01  1.21757804e-01 -2.81185602e-02\n",
      "    1.28837773e-01  8.85650475e-04 -2.45248579e-02 -1.26278815e-02]\n",
      "  [ 2.26244046e-02  7.26471232e-02  1.99324757e-02  4.73620969e-02\n",
      "    1.20350539e-02  3.31280123e-02 -8.37454365e-03 -9.51703066e-02]\n",
      "  [-5.62277835e-02  1.39482513e-01  1.01057511e-01 -2.61051460e-03\n",
      "   -4.15482394e-02 -4.62763733e-03  9.34250017e-02 -4.28961385e-03]\n",
      "  [ 4.67623063e-02 -1.08887755e-01 -9.22190756e-02 -2.42871482e-02\n",
      "   -2.97300527e-02 -1.28309171e-01 -1.22714336e-01  5.33177448e-03]\n",
      "  [ 2.26997328e-02  2.36776400e-02  2.83566081e-02  1.22124614e-01\n",
      "   -2.97812019e-02  9.96865972e-03 -2.21333153e-01 -8.30177360e-02]]\n",
      "\n",
      " [[-1.58167955e-02 -1.14310544e-01  2.81373058e-02  1.73056727e-01\n",
      "   -7.64050004e-02  2.35216429e-02  1.45154579e-02  1.53089783e-01]\n",
      "  [-7.25025814e-02 -1.63907515e-01 -2.56883858e-02 -9.03265363e-02\n",
      "   -2.95471142e-03  5.58847731e-02 -1.09034005e-01 -1.50738593e-02]\n",
      "  [ 3.91691997e-02  1.42332361e-01 -1.52385489e-02 -2.16767546e-02\n",
      "   -4.39177447e-02  1.12311367e-01  1.39733569e-01  8.96054646e-02]\n",
      "  [ 3.20824265e-02  6.57965249e-02  3.53611375e-03 -3.39703459e-03\n",
      "    1.33513989e-01  5.86010311e-02 -3.88363999e-03  5.58739564e-02]\n",
      "  [ 2.11436709e-01 -1.88641762e-01  1.79158654e-01 -1.62671292e-01\n",
      "    1.58246454e-02  6.16539733e-02  2.57531059e-03  5.84098243e-02]\n",
      "  [ 1.51409859e-01  2.64310374e-02 -8.15638395e-02  7.06836019e-02\n",
      "    9.18769372e-02  1.16599701e-01  1.65415379e-01 -4.03713063e-02]\n",
      "  [ 3.66331706e-02  5.88793366e-02 -6.87156060e-03  6.90730914e-02\n",
      "    1.73528304e-01  1.16580253e-01 -7.16908317e-04  4.82497118e-02]\n",
      "  [-4.24360466e-02  4.36805543e-02  1.33185624e-02  8.82693894e-02\n",
      "   -1.19654660e-01  1.79543225e-01  8.55509951e-02  1.98099022e-04]\n",
      "  [ 1.47410283e-01  2.11060812e-01 -1.44129808e-01 -1.44201896e-03\n",
      "   -2.05645171e-02 -1.48237339e-02  1.46154773e-01  2.74720826e-02]\n",
      "  [ 1.50714581e-01 -4.12603970e-02  2.91878631e-02  9.89617405e-02\n",
      "   -3.58862016e-02  1.69149831e-02 -4.74708396e-02 -3.95199080e-02]]\n",
      "\n",
      " [[ 4.26756546e-02  6.59240167e-02 -5.71543176e-02 -9.26482692e-03\n",
      "   -3.06896968e-03  4.31811611e-02  1.33301378e-01  7.57895311e-02]\n",
      "  [ 1.13252845e-01  2.27263229e-02  5.78082627e-02 -1.76658367e-02\n",
      "   -7.04635174e-02  7.00027289e-03  6.46383107e-02  2.78101635e-02]\n",
      "  [ 1.76261117e-01 -1.31479151e-01  1.23617772e-01  2.57284626e-02\n",
      "   -1.29027180e-01  5.29967815e-02  1.54257970e-01 -3.70600708e-02]\n",
      "  [-3.02421785e-03 -1.57817504e-03 -8.87313900e-03 -5.54959037e-02\n",
      "    7.66074374e-02 -7.50725760e-02  5.00452238e-02  1.57810016e-01]\n",
      "  [-2.96815824e-02  5.60612378e-02  2.11984150e-02 -1.33271326e-01\n",
      "    1.02989643e-01  6.03377090e-02  1.68665651e-01 -1.72231260e-01]\n",
      "  [-1.46977573e-01  1.54434532e-01  7.16252803e-02  8.84568937e-02\n",
      "    6.41367934e-02  5.44002028e-02  8.43214183e-02 -3.03433448e-03]\n",
      "  [-2.39215606e-02  1.16068956e-01 -2.39481507e-02 -2.62566169e-02\n",
      "   -3.28541718e-02 -2.08521757e-01 -1.68655697e-01 -9.26747125e-02]\n",
      "  [ 6.82394307e-02 -2.23569623e-02  1.48809661e-01  8.10288153e-02\n",
      "    5.32014233e-02 -8.33159277e-02  4.91873040e-02 -1.02123773e-01]\n",
      "  [ 6.19403924e-02  4.03132041e-02  7.43702811e-02  7.62010468e-03\n",
      "   -8.52499731e-02 -1.87940877e-01 -2.46833106e-01  1.38853054e-01]\n",
      "  [ 9.30377878e-02  1.66095559e-01  3.10868150e-02  6.15773652e-02\n",
      "   -2.33545487e-02  2.29512274e-01  7.16156709e-02 -1.56250540e-01]]\n",
      "\n",
      " [[-8.14110483e-03 -3.95936986e-02  2.23272956e-01 -1.07863244e-01\n",
      "    1.70935499e-01  1.89376540e-02  1.50495109e-02 -7.26213023e-02]\n",
      "  [-9.53500740e-02  3.33245777e-02 -7.91560475e-02  6.65935550e-02\n",
      "    5.45727590e-02  2.55405212e-03  1.12268425e-01  1.55750288e-01]\n",
      "  [-1.03166102e-01  1.23503474e-01  8.42173608e-02 -1.08165722e-01\n",
      "    1.09277754e-01 -2.00366767e-02 -5.25666145e-02 -5.81640263e-02]\n",
      "  [-2.19149175e-01  7.89436156e-02  7.01760468e-03  1.10547797e-02\n",
      "   -5.08153515e-02  3.23297939e-02 -1.02013842e-01 -5.52194660e-02]\n",
      "  [-5.91214264e-02 -1.79411055e-01  2.01218563e-01  3.55274917e-02\n",
      "    4.53873834e-02 -4.16271199e-02  6.10383577e-02  1.73423364e-02]\n",
      "  [ 7.43638927e-02 -1.12208056e-01  2.74350252e-02 -1.08085295e-02\n",
      "    3.41773657e-02  8.09316197e-02 -1.38533410e-01  5.41232551e-02]\n",
      "  [ 9.96198465e-02  7.73468921e-02 -1.64064443e-01 -3.63135979e-03\n",
      "   -1.90017588e-01  1.04320136e-01  6.32042185e-03 -2.23807667e-01]\n",
      "  [-9.91098036e-02  3.57248583e-02  6.05014936e-02  1.75063580e-01\n",
      "   -1.58396759e-02  6.71818705e-02 -1.45616474e-01  9.43558029e-02]\n",
      "  [ 5.42213941e-02  1.18097481e-01  2.19569888e-01 -1.40516564e-01\n",
      "    1.47142287e-01 -9.53552952e-02  7.39596280e-02 -1.21551718e-02]\n",
      "  [-6.46351819e-02  3.28221161e-02  5.79577472e-03  3.36624664e-02\n",
      "    7.99485662e-02  2.62888848e-02 -1.92085031e-02 -1.16784350e-01]]\n",
      "\n",
      " [[-1.15560771e-01  1.16889467e-01 -1.11247969e-01 -1.43093845e-02\n",
      "    3.29863859e-02 -1.60294469e-01 -6.14957057e-02 -3.78775168e-04]\n",
      "  [ 2.52001943e-02  8.85498584e-03  7.66089719e-02  1.13205066e-01\n",
      "   -9.74293024e-02  2.66861410e-02  1.93770925e-02 -1.11512892e-01]\n",
      "  [-1.48526526e-02 -2.23074229e-02  5.48570594e-02  3.11610913e-02\n",
      "   -1.72848021e-01 -8.77210821e-02  7.72370988e-02 -9.29861244e-02]\n",
      "  [-4.20744157e-02  4.83260552e-02  3.41631587e-02  1.77413039e-01\n",
      "   -7.39994420e-02 -9.40145640e-03 -7.77631524e-02  1.79774297e-01]\n",
      "  [ 9.34140107e-02 -5.23759880e-02  1.07418418e-01  1.20007840e-01\n",
      "    1.71207966e-01  1.65880516e-01  5.55522801e-02 -6.42138215e-02]\n",
      "  [ 7.46229219e-02 -1.24996023e-01  8.35389722e-02 -7.68514761e-02\n",
      "   -5.54102858e-02 -1.69858106e-01  1.34823471e-02 -7.85548265e-02]\n",
      "  [-1.61578351e-01 -8.45781299e-02  4.84843912e-03 -1.99032560e-01\n",
      "    1.08587489e-01 -1.25576725e-02  4.38913846e-02  7.61648670e-02]\n",
      "  [ 7.09878523e-02  1.21055682e-01 -1.27659561e-01 -4.34474808e-02\n",
      "   -4.60064635e-02 -2.99883875e-01 -1.04910503e-01 -2.76069504e-02]\n",
      "  [ 7.47637871e-02  4.81524937e-03  7.91078480e-02  2.49736817e-02\n",
      "    6.89733809e-02 -8.41087707e-02 -1.61537351e-02  1.01728061e-02]\n",
      "  [ 2.08288651e-01 -1.44264414e-01  4.35398558e-02 -7.47732507e-02\n",
      "   -5.65189366e-02 -3.12573825e-02  1.75266114e-01  2.88889091e-01]]\n",
      "\n",
      " [[-1.46886349e-01  7.47833999e-02  1.02234404e-03  2.06514302e-01\n",
      "    8.25930297e-02  4.83492568e-02  6.33918270e-02  9.80907176e-03]\n",
      "  [-9.75122339e-02  1.02692150e-01 -1.55884428e-02  1.87579980e-02\n",
      "    1.42617714e-01  6.55131190e-02 -6.13677620e-02  8.38730101e-02]\n",
      "  [ 1.66166589e-01  7.57728210e-02 -2.04164721e-01  1.03504604e-01\n",
      "    7.18578628e-02  6.09545375e-02 -5.09821947e-02 -2.82629138e-02]\n",
      "  [ 5.98459269e-03 -5.27699672e-02  1.54806798e-01 -7.67452552e-02\n",
      "   -8.33073633e-02 -1.73132698e-02 -3.75904057e-01  3.17330782e-02]\n",
      "  [-1.14576339e-01  2.70648972e-02  1.02243810e-01 -1.70061595e-02\n",
      "    2.23051456e-02  4.26127212e-02  7.36693320e-02 -1.16653480e-01]\n",
      "  [ 1.43594560e-02 -1.20670881e-01 -4.01347213e-02  6.00577174e-02\n",
      "    1.61068190e-01  1.69436371e-02 -6.62964188e-02 -3.50326834e-02]\n",
      "  [ 1.24878079e-01 -3.90849145e-03  1.83430629e-01  1.37797217e-01\n",
      "    4.93509247e-02 -1.56828335e-01  1.08800005e-02  5.57114595e-02]\n",
      "  [-8.18963781e-02 -2.50569738e-02 -1.18282720e-02 -3.15453766e-03\n",
      "   -4.99159123e-02 -1.05613287e-01 -9.50464358e-02  4.90077425e-02]\n",
      "  [ 1.32194205e-01 -1.45720744e-02 -7.13306642e-02  8.22415394e-02\n",
      "    1.08265015e-01 -9.83265252e-02  1.38205077e-01 -1.21194462e-01]\n",
      "  [ 4.72603853e-03  8.86069022e-02  4.12787538e-02  3.65571283e-02\n",
      "    2.46101311e-02  7.76493826e-02 -9.82162066e-02  9.66819770e-03]]\n",
      "\n",
      " [[-1.75932998e-01  8.47034585e-02 -5.80239972e-02 -2.26346681e-02\n",
      "    5.76388820e-02 -2.33650761e-02 -1.70683590e-02 -1.22618219e-01]\n",
      "  [ 1.10041095e-01 -4.90419508e-02 -1.38160763e-01 -6.21049240e-02\n",
      "   -6.87585209e-02  1.55036454e-01  6.33928225e-02  9.59794666e-02]\n",
      "  [-1.62999704e-01  1.47526128e-02  4.45898624e-02 -3.89128779e-02\n",
      "   -7.12948424e-03 -1.03103589e-01 -3.53435361e-02  1.06264491e-01]\n",
      "  [ 1.77518883e-01 -1.08157264e-01  1.21577212e-01 -8.93658191e-02\n",
      "    1.50742189e-01  2.02923381e-02 -9.44982831e-02  1.25900959e-03]\n",
      "  [-8.03479384e-02 -1.44738969e-01  4.29174897e-03 -5.95305360e-02\n",
      "    4.07718739e-02 -2.04708511e-02 -1.37589811e-02  8.18822198e-02]\n",
      "  [-1.10069008e-01 -5.72099566e-02 -6.02570082e-02 -5.76539096e-02\n",
      "    1.30941635e-02 -4.81649146e-02 -1.34909434e-01  6.20660852e-02]\n",
      "  [-1.21641878e-01 -2.14481535e-01  6.71734595e-02  1.19082204e-02\n",
      "   -2.71393549e-01 -1.48568872e-01  1.60864510e-01 -6.03273167e-02]\n",
      "  [ 1.39245906e-01  8.05624069e-02  1.74611831e-01  1.60349666e-03\n",
      "   -1.20947597e-01 -2.32972417e-02 -3.27226606e-02  3.48131554e-02]\n",
      "  [ 1.01486701e-01  8.48037153e-02  1.32406691e-01  1.06162757e-01\n",
      "    1.12545581e-01 -3.69083924e-02 -7.41768458e-02  3.88285470e-02]\n",
      "  [ 1.11929124e-01  2.57391200e-02  1.24176132e-01  2.18091857e-02\n",
      "   -5.63971724e-02  2.03580830e-01  2.77399941e-04 -2.10661272e-02]]\n",
      "\n",
      " [[-1.15231715e-03  1.17047731e-01  4.48347415e-02 -1.10632910e-01\n",
      "    7.83490209e-02 -5.03308530e-02 -1.21497144e-01 -1.11384568e-01]\n",
      "  [-1.30074345e-01 -5.43031617e-02  1.42748053e-01  1.14614663e-01\n",
      "   -7.73132034e-02 -4.09686867e-02  2.04490335e-01  5.68674679e-02]\n",
      "  [ 1.00101909e-02 -3.03145481e-02 -9.92915522e-02 -6.92636911e-02\n",
      "    5.46622527e-02 -7.13182931e-02  1.03429548e-02 -1.00810346e-01]\n",
      "  [ 1.27522348e-01  1.20321692e-02  8.00334028e-02  1.24480803e-02\n",
      "   -1.17494838e-02 -2.05393446e-01  4.05920903e-02 -1.07476820e-02]\n",
      "  [ 1.14662745e-01  7.94440855e-02  5.99469770e-02  1.39045640e-02\n",
      "   -1.94794436e-01  9.95503553e-04  5.27305327e-02  1.27508591e-01]\n",
      "  [-1.01508475e-01 -1.84234220e-02  3.92521476e-02  2.05252000e-01\n",
      "   -8.17255194e-02 -1.20966838e-01  4.23408436e-03 -1.00473713e-02]\n",
      "  [ 7.14437158e-02  1.30699944e-01 -8.66888359e-02 -1.88361521e-01\n",
      "    1.44669339e-01 -2.86351394e-03  1.67537928e-02  6.61749910e-02]\n",
      "  [-9.55678633e-02 -9.45678053e-02  4.73221199e-02 -1.77124330e-02\n",
      "    2.90816669e-02 -2.07919132e-01  1.36818952e-01 -9.46976166e-02]\n",
      "  [ 6.56361183e-02  1.55634176e-01 -1.35768446e-01  1.45417758e-02\n",
      "    2.50435000e-01  1.49186007e-01  3.58741710e-02  4.35193209e-02]\n",
      "  [-4.09923697e-02 -1.26060811e-01 -2.62746085e-02  4.46969208e-02\n",
      "    9.78709528e-02 -8.25515319e-02 -1.03982647e-01 -1.67314502e-01]]\n",
      "\n",
      " [[ 1.26814792e-01  2.02657123e-01 -1.79250016e-03  1.29179127e-01\n",
      "   -3.96976107e-02  2.23257635e-01  9.62113910e-02  5.63674618e-02]\n",
      "  [-5.47137059e-02 -5.57355340e-02  1.20589863e-01  3.92879642e-02\n",
      "    1.78193996e-01  9.56100599e-02 -1.17376686e-01  9.15224910e-02]\n",
      "  [-1.53595068e-01 -7.92260765e-03 -2.89246470e-02 -3.88141884e-02\n",
      "   -1.45768360e-01 -2.88365723e-02 -4.93988359e-02  2.55255209e-02]\n",
      "  [ 7.84989736e-02 -3.42474326e-03  2.08305449e-01  1.26411401e-01\n",
      "   -1.70587714e-02 -6.31987136e-02 -1.18923409e-01  2.56434986e-02]\n",
      "  [ 9.95115444e-02  1.13390551e-01  1.01072278e-01 -1.39568886e-01\n",
      "   -1.91320358e-02 -8.69258109e-02  1.75149898e-02 -7.44143222e-02]\n",
      "  [ 1.28563619e-01 -1.59826619e-01  1.29219090e-02  4.21436432e-02\n",
      "   -4.85961167e-02  1.94446908e-01  7.75720404e-02 -1.30179628e-01]\n",
      "  [ 8.33376982e-02 -6.63233984e-02 -8.78566394e-02 -9.95137233e-02\n",
      "   -1.60770838e-02 -4.62878176e-02  1.91438335e-01  6.17873081e-02]\n",
      "  [-5.30905373e-02  2.14815143e-01 -9.79403532e-02  3.37549038e-02\n",
      "    2.01765539e-02 -9.87626112e-02 -1.03272190e-01  2.65373769e-01]\n",
      "  [-3.36600589e-02 -2.54369832e-01 -1.22146468e-02  1.04789027e-02\n",
      "    9.67910966e-02  6.06745111e-02  1.91685858e-01 -7.36761506e-03]\n",
      "  [ 2.34691107e-02  2.22594641e-02  1.42020881e-02 -3.64254976e-02\n",
      "   -6.82925017e-02  3.84456337e-02  4.07785619e-02 -1.15851435e-01]]\n",
      "\n",
      " [[-3.20345248e-02 -7.79186144e-02  1.12614774e-01  1.36993011e-02\n",
      "    4.43274680e-02 -2.31790560e-02 -1.26989141e-01  1.76466815e-02]\n",
      "  [ 7.43062312e-02  2.25651548e-01 -1.25297548e-01 -4.03411008e-02\n",
      "    8.46104099e-02  1.08639604e-01  9.89966567e-02  3.56017183e-02]\n",
      "  [-7.24060255e-02  2.81300229e-02 -8.55043597e-02 -1.43122211e-01\n",
      "   -3.09296857e-02 -1.19579954e-01  6.65944172e-02  1.11414202e-02]\n",
      "  [ 1.84715688e-01 -1.59212599e-01  3.56978894e-02 -1.73775327e-01\n",
      "    1.79261464e-02 -1.29640542e-01  8.88200503e-04  3.02237554e-02]\n",
      "  [-8.80680726e-02 -5.99431371e-02 -9.87497435e-02  2.00031606e-02\n",
      "   -2.13157249e-01 -1.07302166e-01  9.74472780e-02 -2.13755829e-01]\n",
      "  [ 1.23159913e-01 -2.13351370e-02 -8.89192660e-02 -4.91497079e-03\n",
      "   -9.57464123e-02  1.29013811e-01  8.01283921e-03 -4.06147493e-02]\n",
      "  [ 1.39935279e-01 -1.73546800e-02  1.65102916e-01 -1.02181809e-01\n",
      "   -3.16291579e-02 -4.89356688e-02 -1.24413753e-02  9.15159035e-02]\n",
      "  [-1.22510433e-01 -7.00807422e-02 -5.17020311e-02 -4.58751103e-02\n",
      "    4.77296428e-02 -3.26573347e-02  8.20652338e-03 -1.24087804e-01]\n",
      "  [ 4.07718726e-02  1.04189254e-01  1.01765836e-01  2.97288404e-03\n",
      "    1.10600112e-01  5.57499028e-02  4.81248032e-02  1.69144189e-01]\n",
      "  [-9.62499609e-02  7.65537963e-02 -1.01435817e-01  1.24668428e-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    8.94447540e-02 -3.90337219e-02 -2.74642511e-02  5.88405619e-02]]]\n",
      "float64\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "thetas = 1/ENCODING_SIZE*np.random.randn(2 * NUM_QUBITS*NUM_LAYERS*NUM_CLASSES)\n",
    "bias = np.zeros(NUM_CLASSES)\n",
    "thetas = thetas.reshape(NUM_CLASSES, NUM_LAYERS, 2*NUM_QUBITS)\n",
    "init_thetas = thetas.copy()\n",
    "init_bias = bias.copy()\n",
    "print(thetas)\n",
    "print(thetas.dtype)\n",
    "print(bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 28, 28])\n",
      "16\n",
      "tensor([[34.0791, 16.3503,  0.0000,  6.2933, 15.7613,  8.4485, 13.8792,  8.8617,\n",
      "         15.9863,  0.0000]])\n",
      "torch.Size([1, 10])\n",
      "[ 0.164 -0.134  0.254 -0.204]\n"
     ]
    }
   ],
   "source": [
    "# this is the transformation that you need to do in order\n",
    "# to pass it to the encoder. it is (1, -1) since the first number\n",
    "# is the batch size, which in our case is 1\n",
    "enums = enumerate(train_loader, 0)\n",
    "i, data = next(enums)\n",
    "inputs, labels = data\n",
    "print(inputs.size())\n",
    "print(len(labels))\n",
    "print(encoder(inputs[0].view(1, -1)))\n",
    "print(encoder(inputs[0].view(1, -1)).size())\n",
    "print(circuit_tighten(inputs[0].view(1, -1).numpy(), MASK, thetas[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 10])\n",
      "torch.Size([16])\n",
      "(10, 10, 8)\n",
      "298.378751039505\n"
     ]
    }
   ],
   "source": [
    "# Using normal qml.grad\n",
    "X = encoder(inputs.view(len(labels), -1))\n",
    "print(X.size())\n",
    "print(labels.size())\n",
    "print(thetas.shape)\n",
    "start = time.time()\n",
    "dcost = qml.grad(cost, argnum=[2, 3])\n",
    "theta_grad, bias_grad = dcost(X.numpy(), labels.numpy(), thetas, bias) \n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 3, 6, 9, 7, 6, 5, 6, 0, 9, 7, 6, 7, 1, 7, 3]\n",
      "[9, 7, 0, 3, 7, 6, 7, 7, 9, 5, 1, 3, 0, 0, 6, 6]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1875"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def accuracy(thetas, bias, number_batches=2):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(test_loader, 0):\n",
    "        if i == number_batches:\n",
    "            break\n",
    "        inputs, labels = data\n",
    "        inputs = encoder(inputs.view(len(labels), -1)).numpy()\n",
    "        predicted = []\n",
    "        for image in inputs:\n",
    "            scores = []\n",
    "            for i in range(NUM_CLASSES):\n",
    "                scores.append(np.mean(circuit_tighten(image, MASK, thetas[i]) + bias[i]))\n",
    "            predicted.append(np.argmax(scores))\n",
    "        correct += (np.asarray(predicted) == labels.numpy()).sum()\n",
    "        total += len(predicted)\n",
    "        print(predicted)\n",
    "    return(correct / total)\n",
    "# have done no training, so should be around 10%\n",
    "accuracy(thetas, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overfit like crazy on the first 16 examples\n",
    "# Five minutes a batch\n",
    "overfit = []\n",
    "for i, data in enumerate(train_loader, 0):\n",
    "    overfit.append((i, data))\n",
    "    if i == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etas = [1e-2]\n",
    "start = time.time()\n",
    "for eta in etas:\n",
    "    for epoch in range(2):\n",
    "        for i, data in overfit:\n",
    "            inputs, labels = data\n",
    "            X = encoder(inputs.view(len(labels), -1))\n",
    "            dcost = qml.grad(cost, argnum=[2,3])\n",
    "            theta_grad, bias_grad = dcost(X.numpy(), labels.numpy(), thetas, bias)\n",
    "            loss = cost(X.numpy(), labels.numpy(), thetas, bias)\n",
    "            losses.append(loss)\n",
    "            thetas -= eta * theta_grad\n",
    "            bias -= eta * bias_grad\n",
    "            acc = accuracy(thetas, bias)\n",
    "            accuracies.append(acc)\n",
    "            print(\"%d batches took %f seconds and has accuracy %f, with train loss %f\" % (i + 1, time.time() - start, acc, loss))\n",
    "            if i == 1:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.26115204 -0.3566882   0.21375244  0.26802265  0.17610137  0.17953427\n",
      " -0.36239343 -0.25913459  0.14466537 -0.26501191]\n",
      "3.032844949133936\n"
     ]
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.show()\n",
    "print(bias)\n",
    "diff_thetas = thetas - init_thetas\n",
    "print(np.sqrt(np.sum(diff_thetas*diff_thetas)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 3, 8, 3, 5, 8, 2, 9, 5, 4, 1, 4, 7, 0, 0, 6])\n",
      "[2, 3, 5, 8, 2, 8, 2, 5, 5, 4, 1, 4, 3, 0, 3, 3]\n",
      "0.5625\n"
     ]
    }
   ],
   "source": [
    "# Peek at train accuracy:\n",
    "for i, data in overfit:\n",
    "    inputs, labels = data\n",
    "    inputs = encoder(inputs.view(len(labels), -1)).numpy()\n",
    "    predicted = []\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for image in inputs:\n",
    "        scores = []\n",
    "        for i in range(NUM_CLASSES):\n",
    "            scores.append(np.mean(circuit_tighten(image, MASK, thetas[i]) + bias[i]))\n",
    "        predicted.append(np.argmax(scores))\n",
    "    correct += (np.asarray(predicted) == labels.numpy()).sum()\n",
    "    total += len(predicted)\n",
    "    print(labels)\n",
    "    print(predicted)\n",
    "    print(correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 7, 8, 4, 6, 5, 9, 4, 8, 7, 8, 1, 0, 9, 3, 7])\n",
      "[8, 6, 7, 6, 8, 8, 8, 6, 5, 6, 8, 8, 8, 8, 6, 6]\n",
      "[8, 6, 8, 6, 6, 8, 8, 8, 8, 8, 8, 8, 6, 8, 8, 8]\n",
      "1 batches took 16.688527 seconds and has accuracy 0.031250, with train loss 2.297098\n",
      "tensor([2, 3, 1, 1, 8, 3, 1, 5, 4, 5, 1, 0, 2, 6, 7, 0])\n",
      "[5, 6, 7, 6, 1, 5, 8, 6, 8, 6, 8, 8, 8, 8, 6, 1]\n",
      "[5, 6, 5, 6, 6, 5, 8, 7, 5, 5, 8, 3, 8, 6, 8, 4]\n",
      "2 batches took 33.328079 seconds and has accuracy 0.000000, with train loss 2.306482\n",
      "tensor([7, 2, 2, 2, 5, 3, 5, 1, 0, 6, 4, 3, 5, 6, 4, 0])\n",
      "[1, 6, 7, 7, 8, 8, 5, 1, 1, 6, 8, 8, 8, 5, 6, 8]\n",
      "[8, 6, 6, 6, 6, 8, 5, 1, 5, 8, 8, 1, 7, 7, 8, 3]\n",
      "3 batches took 49.407852 seconds and has accuracy 0.000000, with train loss 2.309803\n",
      "tensor([2, 7, 9, 9, 1, 2, 1, 0, 8, 4, 5, 5, 2, 0, 1, 1])\n",
      "[1, 6, 1, 7, 1, 7, 8, 1, 5, 6, 7, 8, 8, 5, 6, 2]\n",
      "[5, 6, 1, 6, 2, 7, 8, 4, 8, 8, 7, 8, 1, 7, 8, 7]\n",
      "4 batches took 65.276373 seconds and has accuracy 0.093750, with train loss 2.295561\n",
      "tensor([4, 6, 0, 7, 2, 5, 9, 8, 9, 1, 7, 7, 2, 7, 6, 7])\n",
      "[1, 6, 6, 7, 7, 7, 8, 7, 7, 6, 7, 8, 8, 8, 7, 7]\n",
      "[8, 6, 8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 1]\n",
      "5 batches took 81.286175 seconds and has accuracy 0.031250, with train loss 2.309128\n",
      "tensor([7, 9, 6, 4, 3, 9, 1, 8, 6, 7, 0, 2, 8, 8, 8, 4])\n",
      "[5, 6, 7, 6, 7, 7, 8, 7, 7, 6, 7, 8, 5, 8, 7, 6]\n",
      "[8, 6, 6, 7, 6, 8, 8, 8, 8, 8, 8, 8, 6, 7, 5, 7]\n",
      "6 batches took 99.010776 seconds and has accuracy 0.000000, with train loss 2.305589\n",
      "tensor([6, 3, 9, 7, 4, 7, 2, 1, 3, 0, 9, 6, 5, 8, 6, 5])\n",
      "[8, 6, 8, 6, 7, 8, 8, 6, 8, 6, 7, 8, 8, 8, 6, 1]\n",
      "[8, 6, 6, 6, 6, 8, 8, 7, 8, 8, 8, 8, 7, 6, 8, 5]\n",
      "7 batches took 117.872795 seconds and has accuracy 0.000000, with train loss 2.299160\n",
      "tensor([4, 4, 6, 8, 4, 1, 0, 1, 3, 5, 3, 0, 0, 3, 8, 6])\n",
      "[8, 6, 8, 6, 1, 8, 8, 6, 8, 6, 4, 8, 8, 8, 7, 8]\n",
      "[8, 6, 8, 7, 6, 7, 8, 7, 8, 8, 8, 8, 8, 7, 8, 3]\n",
      "8 batches took 133.349364 seconds and has accuracy 0.000000, with train loss 2.307235\n",
      "tensor([4, 4, 8, 3, 3, 3, 3, 1, 1, 4, 8, 8, 4, 1, 9, 7])\n",
      "[4, 6, 6, 6, 8, 8, 8, 6, 8, 6, 8, 8, 8, 4, 6, 8]\n",
      "[8, 6, 6, 6, 6, 4, 8, 8, 1, 8, 8, 8, 6, 6, 4, 6]\n",
      "9 batches took 149.566008 seconds and has accuracy 0.000000, with train loss 2.305479\n",
      "tensor([4, 5, 9, 6, 0, 2, 3, 8, 9, 6, 0, 6, 6, 6, 4, 2])\n",
      "[7, 6, 6, 6, 6, 7, 8, 6, 4, 6, 6, 8, 8, 5, 6, 6]\n",
      "[4, 6, 7, 6, 6, 6, 4, 8, 8, 8, 4, 8, 6, 6, 4, 5]\n",
      "10 batches took 167.278590 seconds and has accuracy 0.062500, with train loss 2.306966\n",
      "tensor([1, 1, 6, 8, 7, 5, 4, 4, 0, 7, 3, 6, 5, 2, 5, 5])\n",
      "[8, 6, 6, 6, 6, 6, 8, 6, 4, 6, 6, 8, 4, 8, 6, 8]\n",
      "[8, 6, 7, 6, 6, 4, 8, 6, 1, 4, 8, 4, 6, 6, 8, 8]\n",
      "11 batches took 183.329646 seconds and has accuracy 0.031250, with train loss 2.300415\n",
      "tensor([3, 4, 6, 0, 5, 7, 4, 0, 4, 8, 6, 9, 9, 8, 0, 2])\n",
      "[1, 6, 6, 6, 4, 1, 4, 6, 8, 6, 8, 8, 8, 4, 6, 5]\n",
      "[8, 6, 6, 6, 6, 1, 8, 6, 4, 4, 8, 8, 6, 8, 8, 7]\n",
      "12 batches took 199.292942 seconds and has accuracy 0.156250, with train loss 2.302295\n",
      "tensor([9, 5, 2, 7, 4, 0, 5, 9, 1, 6, 8, 1, 1, 1, 7, 3])\n",
      "[6, 6, 8, 6, 6, 5, 8, 6, 8, 6, 1, 8, 8, 4, 6, 6]\n",
      "[8, 6, 6, 6, 8, 8, 8, 8, 8, 8, 4, 8, 6, 8, 8, 2]\n",
      "13 batches took 215.490604 seconds and has accuracy 0.000000, with train loss 2.295862\n",
      "tensor([8, 9, 5, 2, 1, 7, 9, 2, 6, 8, 5, 8, 1, 0, 2, 2])\n",
      "[8, 6, 6, 6, 6, 6, 8, 6, 8, 6, 1, 8, 8, 8, 6, 6]\n",
      "[4, 6, 6, 6, 6, 6, 8, 6, 6, 8, 8, 8, 6, 6, 8, 1]\n",
      "14 batches took 233.942620 seconds and has accuracy 0.062500, with train loss 2.294891\n",
      "tensor([1, 6, 2, 1, 9, 6, 6, 6, 6, 9, 8, 4, 1, 6, 7, 3])\n",
      "[8, 6, 6, 6, 1, 6, 1, 6, 8, 6, 6, 8, 8, 8, 6, 6]\n",
      "[8, 6, 6, 6, 6, 8, 8, 1, 1, 8, 8, 6, 6, 6, 8, 8]\n",
      "15 batches took 251.010117 seconds and has accuracy 0.000000, with train loss 2.305467\n",
      "tensor([7, 0, 2, 9, 2, 4, 3, 6, 2, 3, 1, 1, 8, 2, 9, 6])\n",
      "[6, 6, 6, 6, 6, 6, 4, 6, 8, 6, 6, 8, 1, 1, 6, 6]\n",
      "[4, 6, 6, 6, 6, 8, 8, 1, 1, 8, 1, 6, 6, 6, 4, 6]\n",
      "16 batches took 268.068780 seconds and has accuracy 0.031250, with train loss 2.312261\n",
      "tensor([3, 2, 6, 0, 7, 4, 3, 7, 2, 2, 1, 7, 4, 3, 8, 6])\n",
      "[6, 6, 6, 6, 6, 1, 8, 6, 1, 6, 8, 8, 4, 4, 6, 6]\n",
      "[8, 6, 6, 6, 6, 8, 8, 6, 6, 8, 4, 8, 1, 6, 8, 6]\n",
      "17 batches took 285.678983 seconds and has accuracy 0.031250, with train loss 2.295919\n",
      "tensor([8, 5, 7, 4, 3, 4, 5, 1, 2, 3, 8, 4, 3, 1, 8, 6])\n",
      "[6, 6, 6, 6, 6, 8, 8, 6, 8, 6, 6, 8, 8, 8, 6, 6]\n",
      "[8, 6, 8, 6, 6, 8, 8, 6, 8, 8, 8, 6, 6, 6, 8, 6]\n",
      "18 batches took 303.415284 seconds and has accuracy 0.000000, with train loss 2.282407\n",
      "tensor([9, 6, 8, 2, 7, 0, 8, 8, 9, 6, 7, 4, 7, 4, 6, 9])\n",
      "[8, 6, 7, 6, 6, 8, 8, 6, 8, 6, 6, 8, 8, 4, 6, 6]\n",
      "[8, 6, 6, 6, 6, 6, 4, 7, 8, 8, 6, 6, 1, 6, 8, 8]\n",
      "19 batches took 321.510444 seconds and has accuracy 0.031250, with train loss 2.300586\n",
      "tensor([1, 1, 7, 7, 7, 5, 4, 7, 9, 2, 8, 3, 5, 4, 2, 6])\n",
      "[8, 6, 6, 6, 6, 4, 4, 6, 8, 6, 7, 8, 8, 4, 6, 8]\n",
      "[8, 6, 6, 6, 6, 8, 8, 6, 8, 8, 6, 8, 6, 6, 8, 6]\n",
      "20 batches took 338.654611 seconds and has accuracy 0.031250, with train loss 2.308179\n",
      "tensor([5, 2, 5, 4, 5, 3, 6, 4, 0, 4, 8, 3, 7, 4, 4, 8])\n",
      "[7, 6, 6, 6, 6, 2, 4, 6, 4, 6, 4, 4, 4, 4, 6, 8]\n",
      "[4, 6, 6, 6, 6, 4, 4, 6, 4, 4, 4, 4, 1, 6, 4, 1]\n",
      "21 batches took 355.942346 seconds and has accuracy 0.156250, with train loss 2.314698\n"
     ]
    }
   ],
   "source": [
    "etas = [1e-1]\n",
    "start = time.time()\n",
    "accuracies = []\n",
    "losses = []\n",
    "for epoch in range(1):\n",
    "    for eta in etas:\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            print(labels)\n",
    "            inputs, labels = data\n",
    "            X = encoder(inputs.view(len(labels), -1))\n",
    "            dcost = qml.grad(cost, argnum=[2,3])\n",
    "            theta_grad, bias_grad = dcost(X.numpy(), labels.numpy(), thetas, bias)\n",
    "            loss = cost(X.numpy(), labels.numpy(), thetas, bias)\n",
    "            losses.append(loss)\n",
    "            thetas -= eta * theta_grad\n",
    "            bias -= eta * bias_grad\n",
    "            acc = accuracy(thetas, bias)\n",
    "            accuracies.append(acc)\n",
    "            print(\"%d batches took %f seconds and has accuracy %f, with train loss %f\" % (i + 1, time.time() - start, acc, loss))\n",
    "            if i == 20:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.08351886 -0.03586817 -0.00538317 -0.03651299 -0.03605283 -0.00593571\n",
      " -0.00632599  0.02434582  0.02424944 -0.00603525]\n",
      "0.014775035931243952\n"
     ]
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.show()\n",
    "print(bias)\n",
    "diff_thetas = thetas - init_thetas\n",
    "print(np.sqrt(np.sum(diff_thetas*diff_thetas)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.08729522 -0.03729522 -0.09329522 -0.04729522]\n",
      "[-0.83772512  1.03827488 -0.79772512  1.03427488]\n",
      "[ 0.91148296  0.59148296 -0.13851704  0.59148296]\n",
      "[0.99986255 0.80186255 0.85586255 0.80586255]\n",
      "[-0.97759454 -0.58759454  0.14840546 -0.58959454]\n",
      "[-0.06805835  0.02194165 -0.06605835  0.01794165]\n",
      "[ 0.8774088 -0.5485912  0.8374088 -0.5565912]\n",
      "[0.98727886 0.26327886 0.22327886 0.26527886]\n",
      "[-0.30220064 -0.23020064 -0.29620064 -0.22220064]\n",
      "[0.25290899 0.97090899 0.33090899 0.97690899]\n"
     ]
    }
   ],
   "source": [
    "#Check for favoritism\n",
    "for i in range(NUM_CLASSES):\n",
    "    print(circuit_tighten(np.random.randn(ENCODING_SIZE), MASK, thetas[i]) + bias[i])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
