{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wide Quantum Circuit Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import pennylane.optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from MNISTData import MNISTData\n",
    "from AutoEncoder import AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODING_SIZE = 10\n",
    "NUM_QUBITS =4\n",
    "NUM_CLASSES= 10\n",
    "# NUM_LAYERS specifies how many times the circuit is run over the qubit wires.\n",
    "# Should increase runtime by a factor of NUM_LAYERS.\n",
    "NUM_LAYERS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dev = qml.device(\"forest.qvm\", device=\"{}q-pyqvm\".format(NUM_QUBITS), shots=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pennylane.ops import RX, RY, CNOT\n",
    "\n",
    "# x will be a length ENCODING_SIZE vector that represents\n",
    "# the encoding of a MNIST image\n",
    "# thetas is of size 2 * NUM_QUBITS\n",
    "@qml.qnode(dev)\n",
    "def circuit(x, thetas):\n",
    "    for i in range(ENCODING_SIZE):\n",
    "        RX(x[i], wires=i)\n",
    "    for j in range(NUM_LAYERS):\n",
    "        for i in range(NUM_QUBITS - 1):\n",
    "            CNOT(wires=[i, i+1])\n",
    "        for i in range(NUM_QUBITS):\n",
    "            RX(thetas[j][i], wires=i)\n",
    "        for i in range(NUM_QUBITS, 2 * NUM_QUBITS):\n",
    "            RY(thetas[j][i], wires=(i - NUM_QUBITS))\n",
    "    return tuple(qml.expval.PauliZ(wires=i) for i in range(NUM_QUBITS))\n",
    "\n",
    "\n",
    "#params: x - input x\n",
    "#        mask - mapping from range(ENCODING SIZE) to range(4)\n",
    "#        thetas - learned parameters\n",
    "#NOTE: Written for NUM_QUBITS = 4\n",
    "@qml.qnode(dev)\n",
    "def circuit_tighten(x, mask, thetas):\n",
    "    for i in range(ENCODING_SIZE):\n",
    "            if i // NUM_QUBITS % 2 == 0: \n",
    "                RX(x[i], wires=i//NUM_QUBITS)\n",
    "            else:\n",
    "                RY(x[i], wires=i//NUM_QUBITS)\n",
    "    for j in range(NUM_LAYERS):\n",
    "        CNOT(wires=[0, 1])\n",
    "        CNOT(wires=[1, 3])\n",
    "        CNOT(wires=[0, 2])\n",
    "        for i in range(NUM_QUBITS):\n",
    "            RX(thetas[j][i], wires=i)\n",
    "        for i in range(NUM_QUBITS, 2 * NUM_QUBITS):\n",
    "            RY(thetas[j][i], wires=(i - NUM_QUBITS))\n",
    "    return [qml.expval.PauliZ(wires=i) for i in range(NUM_QUBITS)]\n",
    "\n",
    "def get_mask():\n",
    "    sub_masks = []\n",
    "    for i in range(ENCODING_SIZE//NUM_QUBITS + 1):\n",
    "        sub_masks.append(np.random.permutation(NUM_QUBITS))\n",
    "    res = np.concatenate(sub_masks).flatten()\n",
    "    return res.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5425\n"
     ]
    }
   ],
   "source": [
    "# example input\n",
    "MASK = get_mask()\n",
    "print(np.mean(circuit_tighten([np.pi/5]*(ENCODING_SIZE), MASK, [[np.pi]*(2 * NUM_QUBITS)]*NUM_LAYERS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: EDITED COST FUNCTION to use bias, and to prevent bias from gaming\n",
    "#       the cost function.\n",
    "def cost(X, actual_labels, thetas, bias):\n",
    "    b = X.shape[0]\n",
    "    yhats = []\n",
    "    for i in range(b):\n",
    "        scores = []\n",
    "        for j in range(NUM_CLASSES):\n",
    "            scores.append(np.mean(circuit_tighten(X[i], MASK, thetas[j]) + bias[j]))\n",
    "        yhats.append(scores)\n",
    "    st = np.stack(yhats)\n",
    "    actual_class_vals = st[range(b), actual_labels]\n",
    "    shifted = st - np.max(st, axis=1)[:, np.newaxis]\n",
    "    the_sum = np.log(np.sum(np.exp(shifted), axis=1)) \n",
    "    # Return loss + regularization term on bias\n",
    "    return np.mean(-actual_class_vals + the_sum + np.max(st, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have to get our (encoded) images so that we may actually start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|██████████████████████████████████████████████████████████████████▍| 9822208/9912422 [00:12<00:00, 1046466.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\n",
      "  0%|                                                                                        | 0/28881 [00:00<?, ?it/s]\n",
      "32768it [00:00, 106649.63it/s]                                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\n",
      "  0%|                                                                                      | 0/1648877 [00:00<?, ?it/s]\n",
      "  1%|█                                                                     | 24576/1648877 [00:00<00:07, 210930.95it/s]\n",
      "  5%|███▊                                                                  | 90112/1648877 [00:00<00:05, 264197.50it/s]\n",
      " 10%|██████▊                                                              | 163840/1648877 [00:00<00:04, 304962.33it/s]\n",
      " 14%|█████████▉                                                           | 237568/1648877 [00:00<00:03, 368369.14it/s]\n",
      " 21%|██████████████▍                                                      | 344064/1648877 [00:00<00:02, 443593.96it/s]\n",
      " 27%|██████████████████▌                                                  | 442368/1648877 [00:00<00:02, 526134.54it/s]\n",
      " 32%|██████████████████████▎                                              | 532480/1648877 [00:01<00:01, 569460.60it/s]\n",
      " 38%|██████████████████████████                                           | 622592/1648877 [00:01<00:01, 629111.82it/s]\n",
      " 45%|██████████████████████████████▊                                      | 737280/1648877 [00:01<00:01, 725143.27it/s]\n",
      " 51%|███████████████████████████████████▎                                 | 843776/1648877 [00:01<00:01, 801596.03it/s]\n",
      " 58%|████████████████████████████████████████                             | 958464/1648877 [00:01<00:00, 864826.18it/s]\n",
      " 65%|████████████████████████████████████████████▎                       | 1073152/1648877 [00:01<00:00, 933022.64it/s]\n",
      " 73%|█████████████████████████████████████████████████▎                  | 1196032/1648877 [00:01<00:00, 997034.80it/s]\n",
      " 82%|██████████████████████████████████████████████████████▉            | 1351680/1648877 [00:01<00:00, 1114964.13it/s]\n",
      " 89%|███████████████████████████████████████████████████████████▉       | 1474560/1648877 [00:01<00:00, 1144148.80it/s]\n",
      " 97%|████████████████████████████████████████████████████████████████▉  | 1597440/1648877 [00:01<00:00, 1114084.17it/s]\n",
      "1654784it [00:02, 807235.29it/s]                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\n",
      "  0%|                                                                                         | 0/4542 [00:00<?, ?it/s]\n",
      "8192it [00:00, 42681.84it/s]                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "data = MNISTData(batch_size=16)\n",
    "train_loader = data.get_train_loader()\n",
    "test_loader = data.get_test_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_from_stem = \"./autoencoder_models/1558731906/\"\n",
    "load_model_from = os.path.join(load_from_stem, \"ae.pt\")\n",
    "load_layers_from = os.path.join(load_from_stem, \"layer_sizes.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9920512it [00:30, 1046466.35it/s]                                                                                      "
     ]
    }
   ],
   "source": [
    "with open(load_layers_from, 'rb') as f:\n",
    "    layer_sizes = pickle.load(f)\n",
    "layer_sizes = layer_sizes[1:]\n",
    "ae = AutoEncoder(layer_sizes)\n",
    "ae.load_state_dict(torch.load(load_model_from))\n",
    "encoder = ae.encoder\n",
    "for child in encoder.children():\n",
    "    for param in child.parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of backend CPU but got backend CUDA for argument #4 'mat1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-0aad2088fcce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m28\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torchsummary\\torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[1;31m# make a forward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;31m# print(x.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;31m# remove these hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1405\u001b[0m         \u001b[1;31m# fused op is marginally faster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1406\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1407\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1408\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected object of backend CPU but got backend CUDA for argument #4 'mat1'"
     ]
    }
   ],
   "source": [
    "summary(encoder, input_size=(28 * 28,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-6.78585071e-02  1.78117656e-02 -7.20868112e-03  8.46867869e-02\n",
      "   -3.18339767e-02  6.24732989e-03 -2.42707438e-02 -4.46353180e-02]\n",
      "  [ 2.62399358e-01 -9.47407240e-02  3.94976471e-02 -9.78486023e-02\n",
      "    6.62962250e-02  2.64429538e-02  7.87796514e-02 -3.93971494e-02]\n",
      "  [-4.20314937e-02 -2.17390872e-02  1.01371850e-01  3.44254246e-02\n",
      "    1.00162936e-01  1.49950090e-01 -1.65052160e-01  6.41760634e-03]\n",
      "  [-3.02023615e-01 -5.90971181e-02 -1.06066674e-01  5.24614749e-02\n",
      "    8.99245202e-02 -4.93045484e-02  4.10534633e-02  2.07723163e-02]\n",
      "  [-2.05823476e-01  6.44673815e-02  5.28275671e-02 -1.16312905e-01\n",
      "   -8.26997459e-02  5.24263870e-02  1.61978660e-01 -7.13220520e-02]\n",
      "  [-4.55717809e-02 -1.16163263e-01  1.21757804e-01 -2.81185602e-02\n",
      "    1.28837773e-01  8.85650475e-04 -2.45248579e-02 -1.26278815e-02]\n",
      "  [ 2.26244046e-02  7.26471232e-02  1.99324757e-02  4.73620969e-02\n",
      "    1.20350539e-02  3.31280123e-02 -8.37454365e-03 -9.51703066e-02]\n",
      "  [-5.62277835e-02  1.39482513e-01  1.01057511e-01 -2.61051460e-03\n",
      "   -4.15482394e-02 -4.62763733e-03  9.34250017e-02 -4.28961385e-03]\n",
      "  [ 4.67623063e-02 -1.08887755e-01 -9.22190756e-02 -2.42871482e-02\n",
      "   -2.97300527e-02 -1.28309171e-01 -1.22714336e-01  5.33177448e-03]\n",
      "  [ 2.26997328e-02  2.36776400e-02  2.83566081e-02  1.22124614e-01\n",
      "   -2.97812019e-02  9.96865972e-03 -2.21333153e-01 -8.30177360e-02]]\n",
      "\n",
      " [[-1.58167955e-02 -1.14310544e-01  2.81373058e-02  1.73056727e-01\n",
      "   -7.64050004e-02  2.35216429e-02  1.45154579e-02  1.53089783e-01]\n",
      "  [-7.25025814e-02 -1.63907515e-01 -2.56883858e-02 -9.03265363e-02\n",
      "   -2.95471142e-03  5.58847731e-02 -1.09034005e-01 -1.50738593e-02]\n",
      "  [ 3.91691997e-02  1.42332361e-01 -1.52385489e-02 -2.16767546e-02\n",
      "   -4.39177447e-02  1.12311367e-01  1.39733569e-01  8.96054646e-02]\n",
      "  [ 3.20824265e-02  6.57965249e-02  3.53611375e-03 -3.39703459e-03\n",
      "    1.33513989e-01  5.86010311e-02 -3.88363999e-03  5.58739564e-02]\n",
      "  [ 2.11436709e-01 -1.88641762e-01  1.79158654e-01 -1.62671292e-01\n",
      "    1.58246454e-02  6.16539733e-02  2.57531059e-03  5.84098243e-02]\n",
      "  [ 1.51409859e-01  2.64310374e-02 -8.15638395e-02  7.06836019e-02\n",
      "    9.18769372e-02  1.16599701e-01  1.65415379e-01 -4.03713063e-02]\n",
      "  [ 3.66331706e-02  5.88793366e-02 -6.87156060e-03  6.90730914e-02\n",
      "    1.73528304e-01  1.16580253e-01 -7.16908317e-04  4.82497118e-02]\n",
      "  [-4.24360466e-02  4.36805543e-02  1.33185624e-02  8.82693894e-02\n",
      "   -1.19654660e-01  1.79543225e-01  8.55509951e-02  1.98099022e-04]\n",
      "  [ 1.47410283e-01  2.11060812e-01 -1.44129808e-01 -1.44201896e-03\n",
      "   -2.05645171e-02 -1.48237339e-02  1.46154773e-01  2.74720826e-02]\n",
      "  [ 1.50714581e-01 -4.12603970e-02  2.91878631e-02  9.89617405e-02\n",
      "   -3.58862016e-02  1.69149831e-02 -4.74708396e-02 -3.95199080e-02]]\n",
      "\n",
      " [[ 4.26756546e-02  6.59240167e-02 -5.71543176e-02 -9.26482692e-03\n",
      "   -3.06896968e-03  4.31811611e-02  1.33301378e-01  7.57895311e-02]\n",
      "  [ 1.13252845e-01  2.27263229e-02  5.78082627e-02 -1.76658367e-02\n",
      "   -7.04635174e-02  7.00027289e-03  6.46383107e-02  2.78101635e-02]\n",
      "  [ 1.76261117e-01 -1.31479151e-01  1.23617772e-01  2.57284626e-02\n",
      "   -1.29027180e-01  5.29967815e-02  1.54257970e-01 -3.70600708e-02]\n",
      "  [-3.02421785e-03 -1.57817504e-03 -8.87313900e-03 -5.54959037e-02\n",
      "    7.66074374e-02 -7.50725760e-02  5.00452238e-02  1.57810016e-01]\n",
      "  [-2.96815824e-02  5.60612378e-02  2.11984150e-02 -1.33271326e-01\n",
      "    1.02989643e-01  6.03377090e-02  1.68665651e-01 -1.72231260e-01]\n",
      "  [-1.46977573e-01  1.54434532e-01  7.16252803e-02  8.84568937e-02\n",
      "    6.41367934e-02  5.44002028e-02  8.43214183e-02 -3.03433448e-03]\n",
      "  [-2.39215606e-02  1.16068956e-01 -2.39481507e-02 -2.62566169e-02\n",
      "   -3.28541718e-02 -2.08521757e-01 -1.68655697e-01 -9.26747125e-02]\n",
      "  [ 6.82394307e-02 -2.23569623e-02  1.48809661e-01  8.10288153e-02\n",
      "    5.32014233e-02 -8.33159277e-02  4.91873040e-02 -1.02123773e-01]\n",
      "  [ 6.19403924e-02  4.03132041e-02  7.43702811e-02  7.62010468e-03\n",
      "   -8.52499731e-02 -1.87940877e-01 -2.46833106e-01  1.38853054e-01]\n",
      "  [ 9.30377878e-02  1.66095559e-01  3.10868150e-02  6.15773652e-02\n",
      "   -2.33545487e-02  2.29512274e-01  7.16156709e-02 -1.56250540e-01]]\n",
      "\n",
      " [[-8.14110483e-03 -3.95936986e-02  2.23272956e-01 -1.07863244e-01\n",
      "    1.70935499e-01  1.89376540e-02  1.50495109e-02 -7.26213023e-02]\n",
      "  [-9.53500740e-02  3.33245777e-02 -7.91560475e-02  6.65935550e-02\n",
      "    5.45727590e-02  2.55405212e-03  1.12268425e-01  1.55750288e-01]\n",
      "  [-1.03166102e-01  1.23503474e-01  8.42173608e-02 -1.08165722e-01\n",
      "    1.09277754e-01 -2.00366767e-02 -5.25666145e-02 -5.81640263e-02]\n",
      "  [-2.19149175e-01  7.89436156e-02  7.01760468e-03  1.10547797e-02\n",
      "   -5.08153515e-02  3.23297939e-02 -1.02013842e-01 -5.52194660e-02]\n",
      "  [-5.91214264e-02 -1.79411055e-01  2.01218563e-01  3.55274917e-02\n",
      "    4.53873834e-02 -4.16271199e-02  6.10383577e-02  1.73423364e-02]\n",
      "  [ 7.43638927e-02 -1.12208056e-01  2.74350252e-02 -1.08085295e-02\n",
      "    3.41773657e-02  8.09316197e-02 -1.38533410e-01  5.41232551e-02]\n",
      "  [ 9.96198465e-02  7.73468921e-02 -1.64064443e-01 -3.63135979e-03\n",
      "   -1.90017588e-01  1.04320136e-01  6.32042185e-03 -2.23807667e-01]\n",
      "  [-9.91098036e-02  3.57248583e-02  6.05014936e-02  1.75063580e-01\n",
      "   -1.58396759e-02  6.71818705e-02 -1.45616474e-01  9.43558029e-02]\n",
      "  [ 5.42213941e-02  1.18097481e-01  2.19569888e-01 -1.40516564e-01\n",
      "    1.47142287e-01 -9.53552952e-02  7.39596280e-02 -1.21551718e-02]\n",
      "  [-6.46351819e-02  3.28221161e-02  5.79577472e-03  3.36624664e-02\n",
      "    7.99485662e-02  2.62888848e-02 -1.92085031e-02 -1.16784350e-01]]\n",
      "\n",
      " [[-1.15560771e-01  1.16889467e-01 -1.11247969e-01 -1.43093845e-02\n",
      "    3.29863859e-02 -1.60294469e-01 -6.14957057e-02 -3.78775168e-04]\n",
      "  [ 2.52001943e-02  8.85498584e-03  7.66089719e-02  1.13205066e-01\n",
      "   -9.74293024e-02  2.66861410e-02  1.93770925e-02 -1.11512892e-01]\n",
      "  [-1.48526526e-02 -2.23074229e-02  5.48570594e-02  3.11610913e-02\n",
      "   -1.72848021e-01 -8.77210821e-02  7.72370988e-02 -9.29861244e-02]\n",
      "  [-4.20744157e-02  4.83260552e-02  3.41631587e-02  1.77413039e-01\n",
      "   -7.39994420e-02 -9.40145640e-03 -7.77631524e-02  1.79774297e-01]\n",
      "  [ 9.34140107e-02 -5.23759880e-02  1.07418418e-01  1.20007840e-01\n",
      "    1.71207966e-01  1.65880516e-01  5.55522801e-02 -6.42138215e-02]\n",
      "  [ 7.46229219e-02 -1.24996023e-01  8.35389722e-02 -7.68514761e-02\n",
      "   -5.54102858e-02 -1.69858106e-01  1.34823471e-02 -7.85548265e-02]\n",
      "  [-1.61578351e-01 -8.45781299e-02  4.84843912e-03 -1.99032560e-01\n",
      "    1.08587489e-01 -1.25576725e-02  4.38913846e-02  7.61648670e-02]\n",
      "  [ 7.09878523e-02  1.21055682e-01 -1.27659561e-01 -4.34474808e-02\n",
      "   -4.60064635e-02 -2.99883875e-01 -1.04910503e-01 -2.76069504e-02]\n",
      "  [ 7.47637871e-02  4.81524937e-03  7.91078480e-02  2.49736817e-02\n",
      "    6.89733809e-02 -8.41087707e-02 -1.61537351e-02  1.01728061e-02]\n",
      "  [ 2.08288651e-01 -1.44264414e-01  4.35398558e-02 -7.47732507e-02\n",
      "   -5.65189366e-02 -3.12573825e-02  1.75266114e-01  2.88889091e-01]]\n",
      "\n",
      " [[-1.46886349e-01  7.47833999e-02  1.02234404e-03  2.06514302e-01\n",
      "    8.25930297e-02  4.83492568e-02  6.33918270e-02  9.80907176e-03]\n",
      "  [-9.75122339e-02  1.02692150e-01 -1.55884428e-02  1.87579980e-02\n",
      "    1.42617714e-01  6.55131190e-02 -6.13677620e-02  8.38730101e-02]\n",
      "  [ 1.66166589e-01  7.57728210e-02 -2.04164721e-01  1.03504604e-01\n",
      "    7.18578628e-02  6.09545375e-02 -5.09821947e-02 -2.82629138e-02]\n",
      "  [ 5.98459269e-03 -5.27699672e-02  1.54806798e-01 -7.67452552e-02\n",
      "   -8.33073633e-02 -1.73132698e-02 -3.75904057e-01  3.17330782e-02]\n",
      "  [-1.14576339e-01  2.70648972e-02  1.02243810e-01 -1.70061595e-02\n",
      "    2.23051456e-02  4.26127212e-02  7.36693320e-02 -1.16653480e-01]\n",
      "  [ 1.43594560e-02 -1.20670881e-01 -4.01347213e-02  6.00577174e-02\n",
      "    1.61068190e-01  1.69436371e-02 -6.62964188e-02 -3.50326834e-02]\n",
      "  [ 1.24878079e-01 -3.90849145e-03  1.83430629e-01  1.37797217e-01\n",
      "    4.93509247e-02 -1.56828335e-01  1.08800005e-02  5.57114595e-02]\n",
      "  [-8.18963781e-02 -2.50569738e-02 -1.18282720e-02 -3.15453766e-03\n",
      "   -4.99159123e-02 -1.05613287e-01 -9.50464358e-02  4.90077425e-02]\n",
      "  [ 1.32194205e-01 -1.45720744e-02 -7.13306642e-02  8.22415394e-02\n",
      "    1.08265015e-01 -9.83265252e-02  1.38205077e-01 -1.21194462e-01]\n",
      "  [ 4.72603853e-03  8.86069022e-02  4.12787538e-02  3.65571283e-02\n",
      "    2.46101311e-02  7.76493826e-02 -9.82162066e-02  9.66819770e-03]]\n",
      "\n",
      " [[-1.75932998e-01  8.47034585e-02 -5.80239972e-02 -2.26346681e-02\n",
      "    5.76388820e-02 -2.33650761e-02 -1.70683590e-02 -1.22618219e-01]\n",
      "  [ 1.10041095e-01 -4.90419508e-02 -1.38160763e-01 -6.21049240e-02\n",
      "   -6.87585209e-02  1.55036454e-01  6.33928225e-02  9.59794666e-02]\n",
      "  [-1.62999704e-01  1.47526128e-02  4.45898624e-02 -3.89128779e-02\n",
      "   -7.12948424e-03 -1.03103589e-01 -3.53435361e-02  1.06264491e-01]\n",
      "  [ 1.77518883e-01 -1.08157264e-01  1.21577212e-01 -8.93658191e-02\n",
      "    1.50742189e-01  2.02923381e-02 -9.44982831e-02  1.25900959e-03]\n",
      "  [-8.03479384e-02 -1.44738969e-01  4.29174897e-03 -5.95305360e-02\n",
      "    4.07718739e-02 -2.04708511e-02 -1.37589811e-02  8.18822198e-02]\n",
      "  [-1.10069008e-01 -5.72099566e-02 -6.02570082e-02 -5.76539096e-02\n",
      "    1.30941635e-02 -4.81649146e-02 -1.34909434e-01  6.20660852e-02]\n",
      "  [-1.21641878e-01 -2.14481535e-01  6.71734595e-02  1.19082204e-02\n",
      "   -2.71393549e-01 -1.48568872e-01  1.60864510e-01 -6.03273167e-02]\n",
      "  [ 1.39245906e-01  8.05624069e-02  1.74611831e-01  1.60349666e-03\n",
      "   -1.20947597e-01 -2.32972417e-02 -3.27226606e-02  3.48131554e-02]\n",
      "  [ 1.01486701e-01  8.48037153e-02  1.32406691e-01  1.06162757e-01\n",
      "    1.12545581e-01 -3.69083924e-02 -7.41768458e-02  3.88285470e-02]\n",
      "  [ 1.11929124e-01  2.57391200e-02  1.24176132e-01  2.18091857e-02\n",
      "   -5.63971724e-02  2.03580830e-01  2.77399941e-04 -2.10661272e-02]]\n",
      "\n",
      " [[-1.15231715e-03  1.17047731e-01  4.48347415e-02 -1.10632910e-01\n",
      "    7.83490209e-02 -5.03308530e-02 -1.21497144e-01 -1.11384568e-01]\n",
      "  [-1.30074345e-01 -5.43031617e-02  1.42748053e-01  1.14614663e-01\n",
      "   -7.73132034e-02 -4.09686867e-02  2.04490335e-01  5.68674679e-02]\n",
      "  [ 1.00101909e-02 -3.03145481e-02 -9.92915522e-02 -6.92636911e-02\n",
      "    5.46622527e-02 -7.13182931e-02  1.03429548e-02 -1.00810346e-01]\n",
      "  [ 1.27522348e-01  1.20321692e-02  8.00334028e-02  1.24480803e-02\n",
      "   -1.17494838e-02 -2.05393446e-01  4.05920903e-02 -1.07476820e-02]\n",
      "  [ 1.14662745e-01  7.94440855e-02  5.99469770e-02  1.39045640e-02\n",
      "   -1.94794436e-01  9.95503553e-04  5.27305327e-02  1.27508591e-01]\n",
      "  [-1.01508475e-01 -1.84234220e-02  3.92521476e-02  2.05252000e-01\n",
      "   -8.17255194e-02 -1.20966838e-01  4.23408436e-03 -1.00473713e-02]\n",
      "  [ 7.14437158e-02  1.30699944e-01 -8.66888359e-02 -1.88361521e-01\n",
      "    1.44669339e-01 -2.86351394e-03  1.67537928e-02  6.61749910e-02]\n",
      "  [-9.55678633e-02 -9.45678053e-02  4.73221199e-02 -1.77124330e-02\n",
      "    2.90816669e-02 -2.07919132e-01  1.36818952e-01 -9.46976166e-02]\n",
      "  [ 6.56361183e-02  1.55634176e-01 -1.35768446e-01  1.45417758e-02\n",
      "    2.50435000e-01  1.49186007e-01  3.58741710e-02  4.35193209e-02]\n",
      "  [-4.09923697e-02 -1.26060811e-01 -2.62746085e-02  4.46969208e-02\n",
      "    9.78709528e-02 -8.25515319e-02 -1.03982647e-01 -1.67314502e-01]]\n",
      "\n",
      " [[ 1.26814792e-01  2.02657123e-01 -1.79250016e-03  1.29179127e-01\n",
      "   -3.96976107e-02  2.23257635e-01  9.62113910e-02  5.63674618e-02]\n",
      "  [-5.47137059e-02 -5.57355340e-02  1.20589863e-01  3.92879642e-02\n",
      "    1.78193996e-01  9.56100599e-02 -1.17376686e-01  9.15224910e-02]\n",
      "  [-1.53595068e-01 -7.92260765e-03 -2.89246470e-02 -3.88141884e-02\n",
      "   -1.45768360e-01 -2.88365723e-02 -4.93988359e-02  2.55255209e-02]\n",
      "  [ 7.84989736e-02 -3.42474326e-03  2.08305449e-01  1.26411401e-01\n",
      "   -1.70587714e-02 -6.31987136e-02 -1.18923409e-01  2.56434986e-02]\n",
      "  [ 9.95115444e-02  1.13390551e-01  1.01072278e-01 -1.39568886e-01\n",
      "   -1.91320358e-02 -8.69258109e-02  1.75149898e-02 -7.44143222e-02]\n",
      "  [ 1.28563619e-01 -1.59826619e-01  1.29219090e-02  4.21436432e-02\n",
      "   -4.85961167e-02  1.94446908e-01  7.75720404e-02 -1.30179628e-01]\n",
      "  [ 8.33376982e-02 -6.63233984e-02 -8.78566394e-02 -9.95137233e-02\n",
      "   -1.60770838e-02 -4.62878176e-02  1.91438335e-01  6.17873081e-02]\n",
      "  [-5.30905373e-02  2.14815143e-01 -9.79403532e-02  3.37549038e-02\n",
      "    2.01765539e-02 -9.87626112e-02 -1.03272190e-01  2.65373769e-01]\n",
      "  [-3.36600589e-02 -2.54369832e-01 -1.22146468e-02  1.04789027e-02\n",
      "    9.67910966e-02  6.06745111e-02  1.91685858e-01 -7.36761506e-03]\n",
      "  [ 2.34691107e-02  2.22594641e-02  1.42020881e-02 -3.64254976e-02\n",
      "   -6.82925017e-02  3.84456337e-02  4.07785619e-02 -1.15851435e-01]]\n",
      "\n",
      " [[-3.20345248e-02 -7.79186144e-02  1.12614774e-01  1.36993011e-02\n",
      "    4.43274680e-02 -2.31790560e-02 -1.26989141e-01  1.76466815e-02]\n",
      "  [ 7.43062312e-02  2.25651548e-01 -1.25297548e-01 -4.03411008e-02\n",
      "    8.46104099e-02  1.08639604e-01  9.89966567e-02  3.56017183e-02]\n",
      "  [-7.24060255e-02  2.81300229e-02 -8.55043597e-02 -1.43122211e-01\n",
      "   -3.09296857e-02 -1.19579954e-01  6.65944172e-02  1.11414202e-02]\n",
      "  [ 1.84715688e-01 -1.59212599e-01  3.56978894e-02 -1.73775327e-01\n",
      "    1.79261464e-02 -1.29640542e-01  8.88200503e-04  3.02237554e-02]\n",
      "  [-8.80680726e-02 -5.99431371e-02 -9.87497435e-02  2.00031606e-02\n",
      "   -2.13157249e-01 -1.07302166e-01  9.74472780e-02 -2.13755829e-01]\n",
      "  [ 1.23159913e-01 -2.13351370e-02 -8.89192660e-02 -4.91497079e-03\n",
      "   -9.57464123e-02  1.29013811e-01  8.01283921e-03 -4.06147493e-02]\n",
      "  [ 1.39935279e-01 -1.73546800e-02  1.65102916e-01 -1.02181809e-01\n",
      "   -3.16291579e-02 -4.89356688e-02 -1.24413753e-02  9.15159035e-02]\n",
      "  [-1.22510433e-01 -7.00807422e-02 -5.17020311e-02 -4.58751103e-02\n",
      "    4.77296428e-02 -3.26573347e-02  8.20652338e-03 -1.24087804e-01]\n",
      "  [ 4.07718726e-02  1.04189254e-01  1.01765836e-01  2.97288404e-03\n",
      "    1.10600112e-01  5.57499028e-02  4.81248032e-02  1.69144189e-01]\n",
      "  [-9.62499609e-02  7.65537963e-02 -1.01435817e-01  1.24668428e-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    8.94447540e-02 -3.90337219e-02 -2.74642511e-02  5.88405619e-02]]]\n",
      "float64\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "thetas = 1/ENCODING_SIZE*np.random.randn(2 * NUM_QUBITS*NUM_LAYERS*NUM_CLASSES)\n",
    "bias = np.zeros(NUM_CLASSES)\n",
    "thetas = thetas.reshape(NUM_CLASSES, NUM_LAYERS, 2*NUM_QUBITS)\n",
    "init_thetas = thetas.copy()\n",
    "init_bias = bias.copy()\n",
    "print(thetas)\n",
    "print(thetas.dtype)\n",
    "print(bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 28, 28])\n",
      "16\n",
      "tensor([[34.0791, 16.3503,  0.0000,  6.2933, 15.7613,  8.4485, 13.8792,  8.8617,\n",
      "         15.9863,  0.0000]])\n",
      "torch.Size([1, 10])\n",
      "[ 0.164 -0.134  0.254 -0.204]\n"
     ]
    }
   ],
   "source": [
    "# this is the transformation that you need to do in order\n",
    "# to pass it to the encoder. it is (1, -1) since the first number\n",
    "# is the batch size, which in our case is 1\n",
    "enums = enumerate(train_loader, 0)\n",
    "i, data = next(enums)\n",
    "inputs, labels = data\n",
    "print(inputs.size())\n",
    "print(len(labels))\n",
    "print(encoder(inputs[0].view(1, -1)))\n",
    "print(encoder(inputs[0].view(1, -1)).size())\n",
    "print(circuit_tighten(inputs[0].view(1, -1).numpy(), MASK, thetas[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 10])\n",
      "torch.Size([16])\n",
      "(10, 10, 8)\n",
      "298.378751039505\n"
     ]
    }
   ],
   "source": [
    "# Using normal qml.grad\n",
    "X = encoder(inputs.view(len(labels), -1))\n",
    "print(X.size())\n",
    "print(labels.size())\n",
    "print(thetas.shape)\n",
    "start = time.time()\n",
    "dcost = qml.grad(cost, argnum=[2, 3])\n",
    "theta_grad, bias_grad = dcost(X.numpy(), labels.numpy(), thetas, bias) \n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 3, 6, 9, 7, 6, 5, 6, 0, 9, 7, 6, 7, 1, 7, 3]\n",
      "[9, 7, 0, 3, 7, 6, 7, 7, 9, 5, 1, 3, 0, 0, 6, 6]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1875"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def accuracy(thetas, bias, number_batches=2):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(test_loader, 0):\n",
    "        if i == number_batches:\n",
    "            break\n",
    "        inputs, labels = data\n",
    "        inputs = encoder(inputs.view(len(labels), -1)).numpy()\n",
    "        predicted = []\n",
    "        for image in inputs:\n",
    "            scores = []\n",
    "            for i in range(NUM_CLASSES):\n",
    "                scores.append(np.mean(circuit_tighten(image, MASK, thetas[i]) + bias[i]))\n",
    "            predicted.append(np.argmax(scores))\n",
    "        correct += (np.asarray(predicted) == labels.numpy()).sum()\n",
    "        total += len(predicted)\n",
    "        print(predicted)\n",
    "    return(correct / total)\n",
    "# have done no training, so should be around 10%\n",
    "accuracy(thetas, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overfit like crazy on the first 16 examples\n",
    "# Five minutes a batch\n",
    "overfit = []\n",
    "for i, data in enumerate(train_loader, 0):\n",
    "    overfit.append((i, data))\n",
    "    if i == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 8, 3, 0, 0, 3, 2, 3, 0, 2, 0, 0, 3, 3, 0, 5]\n",
      "[2, 5, 5, 8, 0, 3, 5, 0, 3, 5, 2, 5, 5, 5, 0, 3]\n",
      "1 batches took 331.432343 seconds and has accuracy 0.093750, with train loss 1.832432\n",
      "[3, 8, 3, 0, 0, 3, 8, 3, 0, 2, 0, 0, 3, 8, 0, 5]\n",
      "[2, 5, 5, 8, 0, 3, 5, 0, 3, 5, 2, 5, 5, 5, 0, 3]\n",
      "1 batches took 665.513576 seconds and has accuracy 0.093750, with train loss 1.830845\n",
      "[3, 8, 3, 0, 0, 3, 2, 3, 0, 2, 0, 0, 3, 8, 0, 5]\n",
      "[2, 5, 5, 8, 0, 3, 5, 0, 3, 5, 2, 5, 5, 5, 0, 3]\n",
      "1 batches took 996.357459 seconds and has accuracy 0.093750, with train loss 1.828978\n",
      "[3, 8, 3, 0, 0, 3, 8, 3, 0, 2, 0, 0, 3, 8, 0, 5]\n",
      "[2, 5, 5, 8, 0, 3, 5, 0, 3, 5, 2, 5, 5, 5, 0, 3]\n",
      "1 batches took 1329.855259 seconds and has accuracy 0.093750, with train loss 1.824682\n"
     ]
    }
   ],
   "source": [
    "etas = [1e-2]\n",
    "start = time.time()\n",
    "for eta in etas:\n",
    "    for epoch in range(4):\n",
    "        for i, data in overfit:\n",
    "            inputs, labels = data\n",
    "            X = encoder(inputs.view(len(labels), -1))\n",
    "            dcost = qml.grad(cost, argnum=[2,3])\n",
    "            theta_grad, bias_grad = dcost(X.numpy(), labels.numpy(), thetas, bias)\n",
    "            loss = cost(X.numpy(), labels.numpy(), thetas, bias)\n",
    "            losses.append(loss)\n",
    "            thetas -= eta * theta_grad\n",
    "            bias -= eta * bias_grad\n",
    "            acc = accuracy(thetas, bias)\n",
    "            accuracies.append(acc)\n",
    "            print(\"%d batches took %f seconds and has accuracy %f, with train loss %f\" % (i + 1, time.time() - start, acc, loss))\n",
    "            if i == 1:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.26158293 -0.3570366   0.21397489  0.26793371  0.17676492  0.17963767\n",
      " -0.36263504 -0.25967539  0.14492601 -0.2654731 ]\n",
      "3.037363042400416\n"
     ]
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.show()\n",
    "print(bias)\n",
    "diff_thetas = thetas - init_thetas\n",
    "print(np.sqrt(np.sum(diff_thetas*diff_thetas)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 3, 8, 3, 5, 8, 2, 9, 5, 4, 1, 4, 7, 0, 0, 6])\n",
      "[2, 3, 5, 8, 5, 8, 2, 5, 5, 4, 1, 4, 3, 0, 3, 3]\n",
      "0.625\n"
     ]
    }
   ],
   "source": [
    "# Peek at train accuracy:\n",
    "for i, data in overfit:\n",
    "    inputs, labels = data\n",
    "    inputs = encoder(inputs.view(len(labels), -1)).numpy()\n",
    "    predicted = []\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for image in inputs:\n",
    "        scores = []\n",
    "        for i in range(NUM_CLASSES):\n",
    "            scores.append(np.mean(circuit_tighten(image, MASK, thetas[i]) + bias[i]))\n",
    "        predicted.append(np.argmax(scores))\n",
    "    correct += (np.asarray(predicted) == labels.numpy()).sum()\n",
    "    total += len(predicted)\n",
    "    print(labels)\n",
    "    print(predicted)\n",
    "    print(correct/total)\n",
    "over_fit_thetas = thetas.copy()\n",
    "over_fit_bias = bias.copy()\n",
    "over_fit_losses = losses.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 3, 8, 3, 5, 8, 2, 9, 5, 4, 1, 4, 7, 0, 0, 6])\n",
      "[3, 8, 3, 0, 0, 3, 8, 3, 0, 7, 0, 0, 3, 3, 0, 5]\n",
      "[8, 5, 5, 8, 0, 3, 5, 0, 3, 5, 5, 5, 5, 5, 0, 3]\n",
      "1 batches took 333.210537 seconds and has accuracy 0.093750, with train loss 2.238850\n",
      "tensor([0, 7, 0, 7, 3, 4, 0, 1, 1, 3, 5, 7, 5, 7, 5, 8])\n",
      "[7, 8, 3, 0, 0, 3, 2, 3, 0, 7, 0, 0, 0, 7, 0, 5]\n",
      "[2, 5, 5, 5, 0, 3, 5, 0, 7, 5, 5, 5, 0, 5, 0, 0]\n",
      "2 batches took 671.998153 seconds and has accuracy 0.156250, with train loss 2.514424\n",
      "tensor([5, 6, 2, 1, 7, 7, 0, 0, 0, 4, 6, 7, 6, 6, 2, 1])\n",
      "[7, 8, 3, 0, 0, 3, 2, 3, 0, 2, 0, 0, 3, 7, 0, 5]\n",
      "[2, 5, 5, 5, 0, 3, 5, 0, 7, 5, 5, 5, 5, 5, 0, 0]\n",
      "3 batches took 992.200486 seconds and has accuracy 0.125000, with train loss 2.495987\n",
      "tensor([3, 2, 9, 1, 9, 9, 7, 8, 1, 3, 4, 5, 5, 2, 9, 2])\n",
      "[7, 8, 3, 0, 0, 3, 2, 3, 0, 7, 0, 0, 7, 7, 7, 5]\n",
      "[2, 5, 5, 8, 0, 3, 5, 0, 7, 5, 5, 5, 5, 5, 0, 7]\n",
      "4 batches took 1338.977725 seconds and has accuracy 0.125000, with train loss 2.391678\n",
      "tensor([4, 0, 9, 2, 8, 1, 4, 7, 6, 3, 6, 6, 7, 4, 7, 3])\n",
      "[7, 8, 3, 0, 0, 3, 2, 3, 0, 2, 0, 0, 3, 7, 0, 5]\n",
      "[2, 5, 5, 8, 2, 3, 5, 0, 7, 5, 5, 5, 5, 5, 0, 7]\n",
      "5 batches took 1671.389423 seconds and has accuracy 0.125000, with train loss 2.308921\n",
      "tensor([1, 1, 5, 6, 2, 3, 8, 8, 2, 5, 8, 7, 0, 9, 4, 2])\n",
      "[7, 8, 3, 0, 0, 3, 2, 3, 0, 2, 0, 0, 3, 6, 0, 5]\n",
      "[2, 5, 5, 8, 0, 3, 5, 0, 7, 5, 5, 5, 0, 5, 0, 3]\n",
      "6 batches took 1985.042257 seconds and has accuracy 0.156250, with train loss 2.280119\n",
      "tensor([6, 4, 6, 8, 3, 0, 5, 7, 3, 0, 0, 3, 6, 2, 9, 6])\n",
      "[7, 8, 3, 0, 0, 3, 8, 0, 0, 2, 0, 0, 0, 6, 0, 8]\n",
      "[8, 8, 5, 8, 0, 0, 0, 0, 0, 5, 5, 5, 0, 5, 0, 0]\n",
      "7 batches took 2299.082081 seconds and has accuracy 0.125000, with train loss 2.427476\n",
      "tensor([8, 5, 1, 6, 5, 1, 0, 0, 2, 8, 0, 9, 6, 0, 8, 6])\n",
      "[7, 8, 3, 0, 0, 3, 8, 8, 0, 2, 0, 0, 0, 6, 0, 8]\n",
      "[8, 8, 5, 8, 0, 3, 0, 0, 7, 8, 6, 5, 8, 5, 0, 0]\n",
      "8 batches took 2613.489920 seconds and has accuracy 0.093750, with train loss 2.419036\n",
      "tensor([2, 7, 8, 6, 1, 1, 9, 8, 1, 3, 4, 8, 1, 2, 7, 6])\n",
      "[7, 8, 3, 0, 0, 3, 8, 8, 0, 2, 0, 0, 8, 6, 0, 8]\n",
      "[8, 8, 5, 8, 0, 3, 5, 0, 3, 8, 8, 5, 8, 5, 0, 0]\n",
      "9 batches took 2927.324291 seconds and has accuracy 0.093750, with train loss 2.346853\n",
      "tensor([9, 2, 2, 8, 5, 3, 0, 6, 9, 4, 5, 8, 7, 4, 3, 3])\n",
      "[7, 8, 3, 2, 0, 3, 2, 8, 0, 2, 0, 0, 6, 6, 0, 8]\n",
      "[2, 8, 5, 8, 2, 3, 0, 0, 6, 6, 6, 6, 6, 5, 1, 0]\n",
      "10 batches took 3240.864452 seconds and has accuracy 0.062500, with train loss 2.377133\n",
      "tensor([0, 7, 6, 6, 9, 1, 2, 6, 9, 2, 2, 6, 1, 4, 9, 9])\n",
      "[6, 8, 3, 2, 0, 3, 2, 3, 0, 2, 0, 0, 6, 6, 0, 1]\n",
      "[2, 8, 5, 8, 2, 3, 5, 0, 6, 6, 6, 1, 6, 5, 1, 0]\n",
      "11 batches took 3554.679902 seconds and has accuracy 0.031250, with train loss 2.357906\n",
      "tensor([1, 5, 3, 4, 2, 3, 1, 9, 0, 9, 5, 0, 2, 2, 6, 5])\n",
      "[6, 8, 3, 2, 0, 3, 2, 3, 0, 2, 0, 0, 6, 6, 0, 1]\n",
      "[2, 9, 5, 8, 2, 3, 5, 0, 6, 6, 2, 1, 6, 5, 9, 0]\n",
      "12 batches took 3869.059824 seconds and has accuracy 0.031250, with train loss 2.295953\n",
      "tensor([5, 4, 1, 6, 2, 3, 9, 9, 0, 3, 6, 9, 1, 4, 0, 2])\n",
      "[6, 8, 3, 2, 0, 3, 2, 6, 2, 2, 0, 0, 6, 6, 0, 1]\n",
      "[2, 9, 6, 8, 2, 3, 5, 0, 6, 6, 2, 1, 1, 5, 9, 0]\n",
      "13 batches took 4182.849100 seconds and has accuracy 0.031250, with train loss 2.324393\n",
      "tensor([2, 7, 9, 4, 0, 1, 6, 9, 2, 1, 1, 7, 6, 3, 4, 4])\n",
      "[6, 8, 3, 2, 0, 3, 2, 9, 0, 2, 0, 0, 6, 6, 0, 1]\n",
      "[2, 9, 9, 8, 2, 3, 5, 0, 6, 6, 2, 1, 1, 5, 9, 3]\n",
      "1 batches took 4494.955101 seconds and has accuracy 0.062500, with train loss 2.402660\n",
      "tensor([1, 5, 1, 3, 3, 9, 2, 2, 9, 7, 0, 5, 3, 8, 6, 1])\n",
      "[6, 8, 3, 2, 0, 3, 2, 6, 0, 2, 0, 0, 6, 6, 0, 1]\n",
      "[2, 9, 6, 8, 2, 3, 5, 0, 6, 6, 6, 1, 1, 5, 1, 0]\n",
      "2 batches took 4807.431080 seconds and has accuracy 0.031250, with train loss 2.276125\n",
      "tensor([4, 7, 7, 5, 8, 6, 9, 1, 1, 6, 6, 3, 7, 0, 3, 6])\n",
      "[6, 8, 3, 2, 0, 3, 2, 6, 0, 2, 0, 0, 6, 6, 0, 1]\n",
      "[2, 9, 6, 8, 2, 3, 5, 0, 6, 6, 2, 1, 1, 5, 1, 0]\n",
      "3 batches took 5123.369850 seconds and has accuracy 0.031250, with train loss 2.392397\n",
      "tensor([5, 4, 0, 1, 0, 9, 0, 2, 1, 5, 8, 2, 1, 3, 0, 2])\n",
      "[6, 8, 3, 2, 0, 3, 2, 9, 1, 2, 0, 0, 6, 6, 0, 1]\n",
      "[2, 9, 9, 9, 2, 3, 5, 0, 2, 6, 2, 1, 1, 5, 9, 0]\n",
      "4 batches took 5436.662768 seconds and has accuracy 0.062500, with train loss 2.331854\n",
      "tensor([9, 8, 2, 2, 1, 7, 0, 4, 3, 5, 9, 1, 2, 1, 9, 9])\n",
      "[6, 8, 3, 2, 0, 3, 2, 9, 0, 2, 0, 0, 6, 6, 0, 1]\n",
      "[2, 9, 9, 9, 2, 3, 0, 0, 1, 6, 2, 1, 1, 9, 9, 0]\n",
      "5 batches took 5748.691947 seconds and has accuracy 0.062500, with train loss 2.303119\n",
      "tensor([0, 0, 6, 1, 9, 6, 4, 1, 3, 6, 0, 8, 8, 9, 2, 4])\n",
      "[6, 8, 3, 2, 0, 3, 2, 6, 0, 2, 0, 0, 6, 6, 0, 1]\n",
      "[2, 9, 1, 9, 2, 3, 0, 0, 1, 6, 2, 1, 1, 9, 9, 0]\n",
      "6 batches took 6061.253754 seconds and has accuracy 0.031250, with train loss 2.198662\n",
      "tensor([1, 6, 6, 2, 3, 7, 0, 1, 0, 3, 4, 4, 9, 0, 8, 2])\n",
      "[6, 8, 3, 2, 0, 3, 2, 9, 0, 2, 0, 0, 6, 6, 0, 1]\n",
      "[2, 9, 9, 9, 2, 3, 0, 0, 1, 6, 2, 1, 1, 9, 9, 0]\n",
      "7 batches took 6373.409614 seconds and has accuracy 0.062500, with train loss 2.394641\n",
      "tensor([8, 4, 4, 0, 3, 4, 4, 9, 1, 9, 9, 4, 7, 3, 7, 7])\n",
      "[6, 8, 3, 2, 0, 3, 2, 6, 1, 2, 0, 0, 6, 6, 0, 1]\n",
      "[1, 9, 1, 9, 2, 3, 0, 0, 1, 6, 6, 1, 1, 9, 9, 0]\n",
      "8 batches took 6685.705103 seconds and has accuracy 0.031250, with train loss 2.401870\n",
      "tensor([5, 1, 8, 7, 1, 6, 2, 6, 7, 8, 9, 1, 0, 7, 6, 5])\n",
      "[7, 8, 3, 2, 0, 3, 2, 9, 1, 2, 0, 0, 6, 6, 0, 1]\n",
      "[2, 9, 1, 9, 2, 3, 0, 0, 1, 6, 1, 1, 1, 9, 1, 7]\n",
      "9 batches took 6997.648362 seconds and has accuracy 0.093750, with train loss 2.337023\n",
      "tensor([9, 7, 2, 8, 9, 1, 1, 3, 1, 2, 2, 1, 5, 7, 7, 8])\n",
      "[7, 8, 3, 2, 0, 3, 2, 9, 1, 2, 0, 0, 6, 6, 0, 1]\n",
      "[1, 9, 1, 8, 2, 3, 0, 0, 1, 6, 2, 1, 1, 5, 9, 0]\n",
      "10 batches took 7311.287235 seconds and has accuracy 0.093750, with train loss 2.385530\n",
      "tensor([8, 0, 5, 7, 3, 2, 5, 0, 2, 0, 1, 8, 8, 2, 7, 1])\n",
      "[7, 8, 3, 2, 0, 3, 2, 9, 1, 2, 0, 0, 6, 6, 0, 1]\n",
      "[2, 9, 1, 8, 2, 3, 0, 0, 1, 6, 2, 1, 1, 5, 9, 7]\n",
      "11 batches took 7625.258274 seconds and has accuracy 0.093750, with train loss 2.312641\n",
      "tensor([3, 5, 9, 8, 2, 6, 7, 9, 6, 2, 9, 5, 0, 7, 7, 5])\n",
      "[7, 8, 3, 2, 0, 3, 2, 9, 1, 2, 0, 0, 0, 6, 0, 1]\n",
      "[2, 9, 1, 8, 2, 3, 0, 0, 1, 6, 2, 1, 1, 5, 1, 0]\n",
      "12 batches took 7938.484244 seconds and has accuracy 0.093750, with train loss 2.379404\n",
      "tensor([5, 1, 8, 3, 7, 0, 8, 1, 2, 8, 0, 8, 3, 0, 2, 5])\n",
      "[7, 8, 3, 2, 0, 3, 2, 9, 1, 2, 0, 0, 6, 6, 0, 1]\n",
      "[2, 9, 1, 8, 0, 3, 0, 0, 1, 6, 2, 1, 1, 5, 1, 0]\n",
      "13 batches took 8253.452615 seconds and has accuracy 0.093750, with train loss 2.425742\n",
      "tensor([4, 7, 6, 3, 0, 1, 0, 6, 1, 3, 0, 1, 5, 4, 7, 9])\n",
      "[7, 8, 3, 2, 0, 3, 2, 9, 1, 2, 0, 0, 6, 6, 0, 1]\n",
      "[2, 9, 1, 8, 0, 3, 0, 0, 1, 6, 2, 1, 1, 5, 1, 0]\n",
      "1 batches took 8570.533272 seconds and has accuracy 0.093750, with train loss 2.267475\n",
      "tensor([2, 2, 8, 6, 1, 2, 6, 5, 0, 8, 1, 4, 5, 3, 6, 4])\n",
      "[7, 8, 3, 2, 0, 3, 2, 9, 1, 2, 0, 0, 6, 6, 0, 1]\n",
      "[2, 9, 1, 8, 2, 3, 0, 0, 1, 6, 2, 1, 1, 5, 1, 0]\n",
      "2 batches took 8888.121603 seconds and has accuracy 0.093750, with train loss 2.249450\n",
      "tensor([2, 4, 2, 3, 2, 0, 5, 7, 8, 3, 7, 3, 1, 5, 4, 7])\n",
      "[7, 8, 3, 2, 0, 3, 2, 9, 1, 2, 0, 0, 6, 6, 0, 1]\n",
      "[2, 9, 1, 8, 0, 3, 0, 0, 1, 6, 1, 1, 1, 5, 1, 0]\n",
      "3 batches took 9205.288091 seconds and has accuracy 0.093750, with train loss 2.389629\n",
      "tensor([8, 4, 5, 9, 5, 8, 8, 4, 9, 1, 5, 0, 9, 7, 2, 5])\n",
      "[7, 8, 3, 2, 0, 3, 2, 9, 1, 2, 0, 0, 6, 6, 0, 1]\n",
      "[2, 9, 1, 8, 2, 3, 0, 0, 1, 6, 2, 1, 1, 5, 1, 0]\n",
      "4 batches took 9522.434605 seconds and has accuracy 0.093750, with train loss 2.359620\n",
      "tensor([5, 0, 4, 3, 2, 0, 6, 3, 1, 8, 5, 3, 0, 0, 7, 2])\n",
      "[7, 8, 3, 2, 0, 3, 2, 9, 1, 2, 0, 0, 0, 6, 0, 1]\n",
      "[2, 9, 1, 8, 2, 3, 0, 0, 1, 6, 2, 1, 1, 5, 9, 0]\n",
      "5 batches took 9839.152232 seconds and has accuracy 0.093750, with train loss 2.351581\n",
      "tensor([7, 7, 0, 9, 2, 2, 1, 3, 7, 9, 2, 3, 0, 1, 3, 6])\n",
      "[7, 8, 3, 2, 0, 3, 2, 9, 1, 2, 0, 0, 0, 6, 0, 1]\n",
      "[2, 9, 1, 8, 0, 3, 0, 0, 1, 6, 2, 1, 1, 5, 1, 0]\n",
      "6 batches took 10154.725977 seconds and has accuracy 0.093750, with train loss 2.364692\n",
      "tensor([9, 9, 5, 1, 0, 8, 7, 6, 0, 1, 8, 7, 7, 6, 1, 6])\n",
      "[7, 8, 3, 0, 0, 3, 2, 9, 1, 2, 0, 0, 0, 6, 0, 1]\n",
      "[1, 9, 1, 8, 0, 3, 0, 0, 1, 6, 1, 1, 1, 5, 1, 0]\n",
      "7 batches took 10472.548656 seconds and has accuracy 0.125000, with train loss 2.473913\n",
      "tensor([4, 7, 6, 8, 0, 3, 5, 5, 1, 7, 1, 2, 5, 9, 3, 8])\n",
      "[7, 8, 3, 2, 0, 3, 2, 9, 1, 2, 0, 0, 0, 6, 0, 1]\n",
      "[2, 9, 1, 8, 0, 3, 0, 0, 1, 6, 2, 1, 1, 5, 1, 0]\n",
      "8 batches took 10790.077224 seconds and has accuracy 0.093750, with train loss 2.416508\n",
      "tensor([2, 8, 2, 4, 3, 4, 6, 6, 8, 9, 2, 8, 8, 7, 1, 2])\n",
      "[7, 8, 3, 2, 0, 3, 2, 9, 1, 2, 0, 0, 0, 6, 0, 1]\n",
      "[2, 9, 1, 8, 0, 3, 0, 0, 1, 6, 2, 1, 1, 5, 1, 7]\n",
      "9 batches took 11107.364819 seconds and has accuracy 0.093750, with train loss 2.327033\n",
      "tensor([4, 2, 9, 7, 1, 4, 2, 7, 9, 4, 9, 5, 0, 6, 9, 1])\n",
      "[7, 8, 3, 2, 0, 3, 2, 9, 1, 2, 0, 0, 0, 6, 0, 1]\n",
      "[1, 9, 1, 8, 0, 3, 0, 0, 1, 6, 1, 1, 1, 5, 1, 0]\n",
      "10 batches took 11423.785274 seconds and has accuracy 0.093750, with train loss 2.216975\n",
      "tensor([1, 4, 1, 5, 1, 0, 9, 7, 1, 4, 4, 8, 0, 6, 8, 1])\n",
      "[7, 8, 3, 2, 0, 3, 2, 9, 1, 2, 0, 0, 6, 6, 0, 1]\n",
      "[2, 9, 1, 8, 2, 3, 0, 0, 1, 6, 1, 1, 1, 5, 1, 0]\n",
      "11 batches took 11740.430124 seconds and has accuracy 0.093750, with train loss 2.444904\n",
      "tensor([0, 4, 8, 7, 7, 1, 4, 4, 1, 2, 4, 3, 2, 8, 3, 2])\n",
      "[7, 8, 3, 2, 0, 3, 2, 9, 0, 2, 0, 0, 0, 6, 0, 1]\n",
      "[1, 9, 1, 8, 0, 3, 0, 0, 1, 6, 1, 1, 1, 5, 1, 0]\n",
      "12 batches took 12056.305016 seconds and has accuracy 0.093750, with train loss 2.473812\n",
      "tensor([0, 7, 2, 6, 4, 6, 3, 0, 3, 1, 6, 6, 2, 3, 4, 6])\n",
      "[7, 8, 3, 2, 0, 3, 2, 9, 1, 2, 0, 0, 0, 6, 0, 1]\n",
      "[2, 9, 1, 8, 2, 3, 0, 0, 1, 6, 2, 1, 1, 5, 1, 0]\n",
      "13 batches took 12374.158665 seconds and has accuracy 0.093750, with train loss 2.208579\n"
     ]
    }
   ],
   "source": [
    "#Time for the real deal.\n",
    "#Gonna start with the overfit weights cause screw it\n",
    "etas = [1, 3e-1, 1e-1]\n",
    "start = time.time()\n",
    "accuracies = []\n",
    "losses = []\n",
    "for epoch in range(1):\n",
    "    for eta in etas:\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            inputs, labels = data\n",
    "            X = encoder(inputs.view(len(labels), -1))\n",
    "            dcost = qml.grad(cost, argnum=[2,3])\n",
    "            theta_grad, bias_grad = dcost(X.numpy(), labels.numpy(), thetas, bias)\n",
    "            loss = cost(X.numpy(), labels.numpy(), thetas, bias)\n",
    "            losses.append(loss)\n",
    "            thetas -= eta * theta_grad\n",
    "            bias -= eta * bias_grad\n",
    "            acc = accuracy(thetas, bias)\n",
    "            accuracies.append(acc)\n",
    "            print(\"%d batches took %f seconds and has accuracy %f, with train loss %f\" % (i + 1, time.time() - start, acc, loss))\n",
    "            if i == 12:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJztvXmcm3d17/8+kkbSSLPvm+2xHcfOZiepCQlJ2PdLy17oEkKBcrmFFlp+99Jy7690+fX+4LaXcn8XKDeQFGhpKYVAKQ2laZs2JCGLExw7thPb8RLbM/Zsnhkto/37++N5Ho08lkaPpEfLSN/36+VXxppH8neU0dHROZ/zOaKUQqPRaDStg6veB9BoNBpNbdGBX6PRaFoMHfg1Go2mxdCBX6PRaFoMHfg1Go2mxdCBX6PRaFoMHfg1Go2mxdCBX6PRaFoMHfg1Go2mxfDU+wD5GBgYUJOTk/U+hkaj0WwYnnzyyTml1KCdaxsy8E9OTrJv3756H0Oj0Wg2DCJy2u61utSj0Wg0LYYO/BqNRtNi6MCv0Wg0LYYO/BqNRtNi6MCv0Wg0LYYO/BqNRtNi6MCv0Wg0LUZLBf5/fOY8J+ci9T6GRqPR1JWWCvy/9a39vO+rTxBNpOp9FI1Go6kbLRP40xlFNJHm5FyE/37fkXofR6PRaOpGywR+K8sf6PDxl4++wAPPzdT5RBqNRlMfWijwpwH48Cu2s3O4k//y7QNcjCTqfCqNRqOpPS0T+CNxI+PvDXj57Lv2sBhN8MnvHkQpVeeTaTQaTW1pmcBvZfwBr5trxrr5rdfs5IfPnOe7Pz1X55NpNBpNbSka+EVkk4g8ICJHROSQiHw0zzUvF5ElEdlv/vndnO+9XkSeE5HjIvLbTv8AdrECf9BnOFF/8KXbeNFkL5/6u0OcW1yp17E0Go2m5tjJ+FPAx5VSVwE3Ax8WkavzXPdjpdT15p8/ABARN/AF4A3A1cAvFLhv1YmYzd2A1w2A2yX8z3deT0YpPv6t/WQyuuSj0Whag6KBXyk1rZR6yvw6BBwBxm0+/k3AcaXUCaVUAvgm8OZyD1sJ0filGT/A5v4An/rZa3j0xAL3PHyyHsfSaDSamlNSjV9EJoEbgMfyfPsWEXlaRH4oIteYt40DZ3KuOUuBNw0R+aCI7BORfbOzs6UcyxZrM36Ld+6d4NVXDfM/fvQcz50POf7vajQaTaNhO/CLSAfwHeBjSqnlNd9+CtiilNoD/G/ge9bd8jxU3pqKUuoupdRepdTewUFbayNLImqqeoLeS7dNigiffvt1dPo8fOxv9hNPpR3/tzUajaaRsBX4RaQNI+h/Qyl179rvK6WWlVJh8+v7gDYRGcDI8DflXDoBTFV86jKIWKoen/uy7w10+Pj023dzZHqZrz1yqsYn02g0mtpiR9UjwN3AEaXUZwtcM2Jeh4jcZD7uPPAEsENEtoqIF3g38H2nDl8K0UQKt0vwuvP/yK+5epgt/QEOnF2q8ck0Go2mtniKX8KtwB3AQRHZb972SWAzgFLqS8A7gP8kIilgBXi3MiajUiLyEeBHgBu4Ryl1yOGfwRaReJqA1435/pSX8Z52Le3UaDRNT9HAr5R6iPy1+txrPg98vsD37gPuK+t0DrKSSF9W31/LRG87DzznfGNZo9FoGomWmdyNJFJ56/u5jPcEmA3FiSV1g1ej0TQvLRP4ozYzfoApXe7RaDRNTMsE/kg8dZmGfy3jZuDXdX6NRtPMtEzgjybSl0zt5mO8xwz8F3Xg12g0zUvLBP5IonjGP9rtx+0SzurAr9FompiWCfxRU865Hh63i5Euvy71aDSapqZlAr+R8RcfWxjvbefsxWgNTqTRaDT1oSUCv1LKrPGvn/EDTPS06xq/RqNpaloi8CfSGdIZZTvjP78cI5nO1OBkGo1GU3taIvBnvfiL1PjB0PJnFJxfilX7WBqNxkGS6UxDD19mMqphFj61RODPevEXkXOCMb0LaGWPRrPB+H9+cJh3/Z+f1PsYBfmj+47wtj97pN7HAOyZtG14svt2bZR6rOldo8HbX81jaTQaBzk8vczTZ5dYjCboCXjrfZxLmA/H+YtHT+P3NEau3RinqDKRuJXxFy/1jPb4AT29q9FsNKYWjfLsT19YrPNJLucbj71AIpUhkkhjGBfXl5YI/KVk/D6Pm6FOn1b2aDQbiFQ6w/llI/A/9cLFOp/mUuKpNF//yWkA0hlFPFV/4UhLBP5sxm+juQtGuUfX+DWajcNMKE7abJw+ebqxAv/fPz3NXDjOq68aBlYT0XrSEoHfeqLtBv7x3oAu9Wg0GwjLUXdLf4Cnzyxm3wTqjVKKr/z4BDuHO3ntNUbgtxLRetISgd9S9RQzabOY6G1nanGlYX55NBrN+liJ2pt2jxJJpHnufKjOJzL4yfPzPHs+xPtum6TTjD9WPKonLRH4V0rN+HvaSWUUMyGt5ddoNgJWY/dNu8eAxqnz3/3QSfqDXt58/XhWTh6J61JPTbCeaDuTu5Djy6/r/BrNhmBqcYWeQBu7RjrpD3obIvA/PxvmX56d4Zdv3oK/zU2HqSrUpZ4aEU2k8Le5cLvWXR2cZVNWy68Dv0azEZhaXGGsux0R4YbNvQ0h6fzzh0/idbv45Zu3AKuJZ1SXempDJJGyJeW0GOvRm7g0mo3EucWV7Ov2xi09nJyLsBBJ1O08i9EE33nyHG+5YYzBTh+wKicP61JPbYjG07aGtywCXg/9Qa+2Z9ZoNghTiyuMm8OXN27uBeCndSz3/NXjL7CSTPO+27Zmb7PcgTdExi8im0TkARE5IiKHROSj61z7IhFJi8g7cm5Li8h+88/3nTp4KZSa8YPly68zfo2m0QnFkizHUtmMf/dEN26X1K3On0hl+Nojp7jtigF2jXRlbw82UHPXTjRMAR9XSj0lIp3AkyJyv1LqcO5FIuIGPgP8aM39V5RS1ztz3PKIJtK021T0WIz3tPPchcaQhGk0msJMm066VuAPeD1cNdrJU6frU+e/7+A0F5bjfPrtuy+53edx4ZIN0txVSk0rpZ4yvw4BR4DxPJf+OvAdYMbREzpAJF56xj/RayxkaQRfDY1GUxirF2cFfjDKPU+fXSRV470aSinufugk2weDvGzH4CXfExGCPs/G0/GLyCRwA/DYmtvHgbcCX8pzN7+I7BORR0XkLWWesyKiieL7dtcy3tNOPJVhLly/BpFGoymONbU7vibwRxPpmn9qf+LURQ6eW+J9t23FlUdFGPR6svtB6ontwC8iHRgZ/ceUUstrvv054BNKqXw/0Wal1F7gF4HPicj2Ao//QfMNYt/s7KzdY9nCWLtYasZv+fLrBq9G08hMLa7gcUlWPQOrDd6naizr/MqPT9AbaONtN0zk/X7A5ya8UTJ+EWnDCPrfUErdm+eSvcA3ReQU8A7gi1Z2r5SaMv97Avg3jE8Ml6GUuksptVcptXdwcDDfJWUTTaRKz/h7taRTo9kITC3GGOn2XzKns6mvnYEOHz+toWHb6fkI9x+5wC+9eEvBnmKHz0N0I9T4RUSAu4EjSqnP5rtGKbVVKTWplJoEvg38mlLqeyLSKyI+83EGgFuBw/keo5pE4qVn/Hp6V6PZGORq+C1EhBs399RU2fPXj5/B4xLec8uWgtcEvG4iG8Sd81bgDuCVObLMN4rIh0TkQ0XuexWwT0SeBh4APr1WDVRt0hnFSrL0Gn+Xv40uv0dLOjWaBsfQ8LdfdvuNW3o5NR9lPhyvyTnOXoyyqTfAUJe/4DVBr6chVD1F02Cl1EOAPa8D4/r35nz9CHBdWSdziJWk/SUsa9H2zBpNY5POKM4vxRjruTzYrg5yLfLqq4erfpZwPEWnf/04E/R5tB9/LbDqaaXq+MFayKKbuxpNozIbipPKqMtKPWAMcnlqOMgViqXoKBr43Q2R8Td94LfqacESLBssxnu0ll+jaWTyafgt/G1urh7rqtlGrnAsRUeRXmKgQUo9zR/4s2sXSy/1TPS2E0mkWVpJOn0sjUbjAPk0/LncuLmXA2eXajLIZZR62ta9JujzEE2mydR5yVPTB/5SFq2vZULbM2s0DY0V+Ee78zdUb9jcw0oyzbM12Mi1HEsWzfiDXjdKQSxV3zp/0wd+azy6FHdOi/Eea4hLB36NphGZWlyh0+8pmGmvDnJVt9yjlCIcT9Flo7kLxqeDetL0gX/FkYxfN3g1mkbk3GKsYJkHjNfwYKePp6pc548m0iiFreYuUHfbhqYP/Ks1/tIz/p5AGwGvW0s6NZoGZSrP8FYuq4Nc1bVuCMWMONPhW7/GH/DqjL8mZGv8JU7ugvFLYyl7NBpN4zG1tJJXw5/LjZt7eWEhylwVB7nCcUMAUkzHb/UA6q3lb/rAn63xl5Hxg6Xlr03gf9sXH+atX3yYo3oPgEZTlEg8xWI0uW7GD8YEL1DVcs+ylfEXCfxWHKq3NXPTB/5oPI1LjCUI5TDe216TUo9SioPnlvjpC4u86f97iC88cJxkjb3ENc3N7//9IX7n3oP1PoZjTC+tL+W0uG68mza3VLXcEzYDf2cxVU92C5cO/FXFWrtoeM2VzkRvgKWVJKFYdbX8yyspkmnFr718O6+5Zpg//tFzvPWLD3N4aq0DtkZTOql0hm8/eZbHTs7X+yiOcW7x0s1bhTAGubqrquyxavZ2dPygm7tVp9RF62uxsolqZ/1zEaP+eOVwJ1/4xRv50i/fyPmlGD/3+Yf40/uPkkjp7F9TPvvPLBKKpViINM9ioal1pnbXcuPmHg6cXazap2grMSyq6tGlntpQzqL1XGplzzxvbvrq7/AC8PprR7n/N1/Gm3aP8r/+5Rg/9/mHOHh2qapn0DQvDx6bA2Axmqz5OsJqMbW4gktgOGcBSyFu3NxLLJnh2enq9M8sVU+x5q6l6tGlnioTTVSW8ddqeteyju0Prv4S9wa9fO7dN/CV9+zlYjTBW774MH+3/1xVz6FpTh48urrVbrFJLEjOLa4w0uXH4y4exrIN3iqVe6xST7Ek0+tx4XW76u7J3wKBP1WWT4/FQNCH1+OqfqnHDPwDnd7Lvvfqq4f5p998GZt627n3KR34NaWxGE1w4Owi2weDAE1T7imm4c9lrNvPcJevaoE/FEsR9Lov2QJWiIDPXfctXC0Q+NPZulo5uFzCRE/17Zmtpe59gcsDP0B3exs3bunl2fO62aspjYePz5NR8NYbxoHVsuJGZ2oxZjvwiwg3bOrl6TPVUfaEY8UN2iyCXg9h3dytLpF4ikAZw1u5jPdWf4hrPhKnN9C27sfWXSOdXFiOsxhtjheupjY8eHSWLr+Hl+8cApoj489kFNNL9jN+gCuGOjhzcaUqDd5QPFm0sWsR9LmJ6uZudak04wdD2VP9Gn+C/o71m1S7RroAauI0qGkOlFI8eGyWW68YYMhsgi40QeIwF46TTCvGi0zt5jI5ECSdUVV5LYdsePFbBLweXeOvNpF4ZTV+MBq885FE1vCtGsyHE/QH85d5LHaNdALw7LQu92js8fxsmOmlGC+9cpAes4y40ASlnvUWsBRi64DhtntqLuL4eeysXbRohC1cTR34lVKGqqfSjL+3+lr+uXCcgSKytMFOH72BNp7Tlg4am/z7UUPGefuOAbweF51+DwuR2iwfryZTNoe3ctnSbzS3T1Yh8IdiJQT+BtjC1dSBP5HOkMqosgzacpnotXz5q9fgnQvHGSiS8YsIu0a6OFIlLbKm+Xjw6CzbBoPZ3+H+oJeF6MaXc5YyvGXRH/TS6fNwer4KGX8sRWcRZ06LRli43tSB3xqLrjjjr/L0biKVYTmWKlrjB9g50snRC6G6r27TND6xZJrHTs7z0h2D2dt6g96myPjPLa7Q4fMUXXySi4iwZSDAyXnnE7hwvPiidYuAdwOUekRkk4g8ICJHROSQiHx0nWtfJCJpEXlHzm13isgx88+dTh3cDtZYdCWTuwDDXX48Lqlag9dSWVhTu+uxa6STaCKtt4JpirLv1EViyQwvvXIge1t/0NsUck5Dw+8v2YNrsj/oeI0/nTG2b9lt7nb4PBvCsiEFfFwpdRVwM/BhEbl67UUi4gY+A/wo57Y+4FPAi4GbgE+JSK8TB7eD1YytZHIXwO0SRnv8VZN0Zoe3bGT8u0YNZc+RDajn//GxWZ45p20nasWDx2bxul3cvK0/e1tf0MvFJlD1TJUo5bTYOhDk7MWoo95XVhC3W+MPeD3EkhnSdfzUXjTwK6WmlVJPmV+HgCPAeJ5Lfx34DjCTc9vrgPuVUgtKqYvA/cDrKz61TSIVrF1cy3hP9eyZVwN/8Yz/yuEOROC5DSjp/M9/e4A/vf9ovY/hOEop/vGZaV75J//GJ759oN7HyfLg0Vn2TvZeomozSj0JlNrYpcJShrdy2dIfJKOc7dfZ9emxsNYv1jPrL6nGLyKTwA3AY2tuHwfeCnxpzV3GgTM5fz9L/jeNqhCtYO3iWiZ6A1Vr7mYN2oLFM/6A18OWvsCGC/zLsSTnl2NcCMXqfRRHOXh2iXfd9Sgf+sunOL0Q5V+fmyl+pxowsxzj2fMhbs+p74NR6kmmFaE615grYSWRZiGSKOrDnw9L0nnawTp/2ObaRYtGsGa2HfhFpAMjo/+YUmptneFzwCeUUmt/knwFuLyphoh8UET2ici+2dnZfJeUTKSCtYtrGe9pZyYUJ55y/n/WvNlss1PjB6PBu9FKPcdnwgBcWN74jUWA80sxfutb+/nZzz/E8zNh/uit1/I7b9jFbCjOheX6v7lZbpy59X2APjO52Mha/qklS9Fjf3jLohqSTrtrFy2sRLSee3dtnVRE2jCC/jeUUvfmuWQv8E2z0TIAvFFEUhgZ/stzrpsA/i3fv6GUugu4C2Dv3r2OfA61xqLbHcj4x3vbUQqmF2NMDgQrfrxc5sMJvB6X7ebQzpEu7j98gVgyjb+t8p+tFhy/YAT+uXCcVDpjy1GxEYkmUtz14An+z7+fIJ1RfOhl2/nwK7bT6W9j36kFAJ45t8RwV+lByUkePDrLQIePq8xpbwtrSHAhmmASZ3+Pa0VWytldesZvSTpPOSjptLt20WJ1724DB34xovndwBGl1GfzXaOU2ppz/VeBHyilvmc2d/97TkP3tcDvVHxqm0TiztX4J3KGuJwO/LPhOIMdPtsKhatGOskoOHYhzHUT3Y6epVocmzFKU0oZhnQj3fUNjOXw42Oz/Oe/PcD55Rj/Yfcov/36XWzqC2S/f9VoFyJw8NwSr7pquG7nzGQUDx2f42VXDuJa4xbZG9z407vlaPgtRITJgSCnqlDqsSstXfXkr1+px85JbwXuAA6KyH7ztk8CmwGUUmvr+lmUUgsi8ofAE+ZNf6CUWqjgvCVhvaNWquoBmOgxXuDVUPYYPj32yjxglHoAnj2/vIECfzj79UwoVlbgtxaI1OvTwp/86DncLuHbH7qFvZN9l30/6POwfbCDZ87Vtwx3aGqZhUjisjIP5GT8G9io7dxiDBHKTh629Ac44OBSI6tkY7/GbzZ3G7nUo5R6iPy1+kLXv3fN3+8B7in5ZA5gvaMGHCiHjHT7cUl1pnfnI0bGb5ct/UH8ba4N1eA9diHM1oEgJ+ciZdf5f+WrTzDW3c5n3rHb4dPZ42I0yYsme/MGfYtrx7p49ETNcpu8PHjM6JHddsXgZd/ryyn1bFSmFlcY7vTTVmYCsHUgyH0Hp0mkMng9lScRdtcuWmQXrm8UVc9GI5pI4fO4HMkQvR4Xo93tnF6oQuC34cyZi9slXDncuWFcOiPxFOcWV7j1CkNPXm7z8/DUcjao1YOllSRd7etnddeOd3N+OcZsqH5N7AePznL1aBeDebyfAl43Xo+rKhn/mYUox2eq/ztpDW+Vi9OSznAshQi2XYCt0nM9bRuaPPCnHVH0WGwbDPL8bLj4hSWglGI+nLA1vJXLzg0U+E/MGo20m7f14xJDalgqsWSa+UiC6aVYXVQzmYwiFEvSbSPwAzwzVZ9BtXA8xZOnL/LSKy/P9sGocVdrevcPfnCYd9/1WFWUb7mUsnkrH1mXTocavMumJbPdHl2gAUo9TR34I4mUIxp+i+2DHZyYjTg6/LIcS5FIZ2wNb+Wya7SLuXA8O/zVyFiN3V0jXQx0+Moq9eQG+2ptUVqPcCJFRlE08F8zZqhoDtVpQvknz8+Tyqi89X2Lak3vTi+tMBeOc9/Baccf2yKTUUwtxcrS8FtMmpLOU3MOZfzxFJ0lJJjBBmjuNnXgj8bTjih6LLYPBokm0px3MOPMLlkvNfCbDd6NUOc/NhOmzS1s6Q8w3OUva4hreikn8J+tfeBfMh0ti5V6Ov1tbB0IcrCMwP/lB0/wlR+fKOt8Fj8+Nkt7m5uf2VLYGaUv6GW+CqWeuZDxmF995LTjj20xH0mQSGUqyvj7HJZ0lrJ2EYxSrb/NVVc5Z1MH/kgi5YiG32L7YAcAz884pwG2XoB2pnZzWVX2bIDAbzZ229wuhrvKy/jPm4G/0+/h6TO1z6aXzQZel40X+LXj3SUrezIZxRf/7Thf/0llQfPBo7Pcsr0fn6fw731fFRw6MxllWIt3+Hj6zCL7q/SprBIpp4XTks5S1i5aGHt3deCvCkaN38HAP2QE/hNzztX550LlZfwDHT4GOnw8twEmeI/PhLjCfO4GO/1l1fitjP/VVw3z9NnFmttSL60Ygb9YqQcMZc+5xRUulpBVHzm/zMVokhcWomXXfl+Yj3JqPspLdxQu84BZ6ok468m/tJIklVG855YtdPg8fO2RU44+vsVq4K9sDmRywDmXznAJS1gs6u3J39SB34m1i7kMdfoIet08P+Ng4DeDQylyTotdI43f4I0l07ywEOWKIeMTynCXj/lIouSF1+eXVujye7hlez+hWIqTVVimsR7LJQT+68po8D58fC779dEyN6xZiqfbCzR2LfqDXsLxlKNNWKvXtKU/wDt+ZoIfHJiqirJpykwAKqnxA0z2Bxxz6QyVYMlsUW9P/qYO/E4sWs9FRNg+1MEJB30+rBp/b5HtW/mwlrLU0961GCdmI2QU7DAzfsvKoNSgML0UY7S7nes39QC1b/BaGX9Xe/EX+DVjRuAvpc7/8PH57JtKuX2bh47NMd7TzrYik+W9VRjisv5/Dnb6eM8tW0imFX/9+AuOPb7F1OIKAa/b1hvwekw6KOksZe2iRbDOnvxNHvhTBByUcwJsGwg6mvHPhxP0BNrKGkbZNdJJLJmxvUru/sMXau6Hf9yUv+4YtgK/8cmmVEnm9JIx7bt9sIOg113zwL+8YrxI7QSc7kAbm/sCHLJZ54+n0jx+coGf2zNGwOsu+1PcgbOL/MyW3qKyQmt610lJ56yZwAx2+Ng22MFLrxzkLx89XfInu2JYUs5SF7CsZdJBSWepzV0wA79W9VSHSNzZjB+MBu/UUsyxjvx8JJ59IZbKLtOAy06GOBOK8WvfeJL3/vnjNR3XP34hhEuMaUmAoU4j4y+1wWtk/H7cLuG6ie6qNQ8LsbSSxO0S2x/prx3vsp3x//SFRVaSaW7fMcCO4c6yMv6LkQRTSzGuHe8qeq3l0OmkpHPOfBOx5lF+5SWTzITi/PCZ8479G1C5ht/CKUlnMp1hJZkuudQT9Lq1qqcaZDKKlWTa0Ro/wDZT2WMNJVXKXKj04S2LHcMduMSesuevHztDMq1YjCb51PcPlfXvlcOxmTCT/cGsysQq9cyUIOlMpDLMheNZb5Y9m3o4PL1c9UGhXJZWknT57Q/pXDvezQsL0awMdD0eOT6HS+DF2/rZNdzJcxdCJc+KHJoyPl1YZab16Asa2anTpZ42t2Q/Eb3sykEm+wOON3nPLcYYr7CxC6ak01+5pDOS9ekpo9SjM37nWUlaXvwOZ/xDRqbg1ATvXCReduD3t7mZHAjybBFlTzKd4RuPneZlVw7yG6/awd8/PcU/PlO9IZtcjs2Es2ooMMoMbpeUVOqxrh01A//1Ez0k04oj07VrbC/Hits15HKtGYAP2WjwPnR8jt0TPXS3t7FzpJOFSCJbOrGL9e9YA2TrYWX8TpZ65sJx+oO+rBuoyyXcccskT56+6Fh5MZZMMxeOl2XHvBYRYbI/WLEvf6nbtyyCXreu8VcD60l1OuOf7A8i4lzGX6oz51p2jRQvDfzo0HlmQnHufMkW/tPLt3PNWBf/7XvPlCQ3LIdEKsOpuUi2sQtGQBjqLE3Lfz4b+I0X/J46NHiXVorbNeRi17ohFEvy9NmlrI9RuYN5h6aWGe9ppydQ/Hepu70Nlzhd6olf5g30zr0TBLxuvupQ1m/NcjhR6gFD0lnpJq5yA3/A59kYG7g2GtaT6qRlAxhZ9kRvuyMZfyKVYWklWfLwVi67Rro4vRBdt1749UdOs7kvwMuuHKLN7eJP3rmHxWiS3/v76pZ8Ts9HSGVUtrFrMdTlLynjt7TbVsY/2u1nsNPX0IG/L+hlvKedg0UavI+dWCCdUdx6haG931lm4H9maomrbWT7YEyO9gScnd6dDcUvsx3p8rfxthvH+f7TU1n1WiU4MbyVixOSTmsIq9TmbofPQyKdcXTpeyk0beCvVsYPq549lWLVWCvJ+HeOdKIUHL2Q/43o8NQyj59a4I6bt+A2P4ZfNdrFr79yB3+3f4ofHXK2+ZaLtW5xh6nhtxjq9JUk57QyPavGLyLsmehhfw2tG4waf2kv7mvHu4p69jz8/Bw+j4sbNxsWC/3mYF4pyp5IPMXJuYitMo9FX9Dr6DIWa2p3LXfeMkkileGbT5zJc6/SOGcG/ko1/BaWpPNMBZJOa+1iOTp+qN8WrqYN/NFEdWr8ANsGOjgxF654etQaeim3xg+5pYH8meXXf3IKf5uLd+6duOT2X3vFdq4e7eK/frd6JZ9jM2FEVq0uLAzbBvsZ//RSjA6f55Ks6vpN3ZyYjWT19dVmeSVVUo0fjDr/iblI1q89Hw8fn+OmrX2XrNC0U77L5dnzyyhlr7Fr0Rf0OubJb9g1JPLaQO8Y7uTWK/r5y0dPZxfplMuUuYBluLv810su1iY9u3LofIRKXLtoYXmI1cu2oWkDv9Vtr0rGPxQklswwXaFZm/VRu1Rnzlw29QYIeN15G52L0QTf23+vBYhVAAAgAElEQVSOt94wflntd7Xkk+D3q1TyOTYTZqK3/TK/pOFOPxejSduqnPNLl2/sun6TkSEfdHCTUiGUUiyXWOoBuNbcjnZ4Kv+b8kwoxtELYV6y/VKLhSuHSxvMW1X0lJDxB7yOqXoWV5KkM6pgAnPnLZNML8X4p8MXKvp3nruwzGCHb10folKY7De0/CcrkHSW3dz11deTv2kDfzUz/lWztsrq/KvOnOVnMC5zKUu+DPFv950llsxwx82Tee979ZhR8vne/in+qQoln2MXQlyxJtuHHEmnzQbv9HIsW9+3sFZO1sKpM5bMkEhnSg/8RSZ4Hzk+D8BtV1wa+HeNdBJP2R/MO3Rumd5A22XP0Xr0dTgX+LOfXPNk/ACvumqYid72ipq8X3jgOPcdPM8brxst+zHWYkk6ncj4O22uXbSotyd/0wZ+6wl10pbZYtugM5JOS05XSY0f4KrRTvPj/mqGmM4o/uLR09w02bdu088q+Xzyu8+w6KDKI5XOcGIuwo7hzsu+N2RO79rV8p9fWrksqHW3t7FtMFiTQa6sM6cNu4ZcBjt9jHT5sxn5Wh4+Pkd3e9tl/3+sBq9dz55D00tcM9Zd0jRrf9DLYjThiN1H1q6hQALjdgl33LyFx08ucGS6dFPBLz94gj/+0XO8+fox/u83XV3RWXNxQtIZjiezNsulUG9P/qYN/JaO32lVDxi/4J1+T8UN3rlwHK/HVdISh3zsHO7kYjR5ScP034/O8MJClPe8ZMu6921zu/jjd+42Sz6HKzpHLmcurpBIZbKunLlYGb8dSWcynWEmFGckj3b7+oke9p9ZdHQxTj5KceZcS6EJXqUUDx+f4yXb+7NNd4srhzsRm4N5yXSGo+fDJZV5wMh2MwpHeiRWxj/YWTiBedeLNuFvc/H5fz1eko3DVx8+yR/dd4T/cN0o//Odey57rirFsGeuIPCbPj2lWkhkF67r5q6zWO+kTq5etBARtg12VJzxz4UTDAS9FfuO7DStG3IDxVcfOc1Qp4/XXTNS9P7XjHXzkVdewXd/eo5/rrAOa7Gq6Fkv8BfP+GdCcZQibxljz6YeZkPxS5a0VIPKAn83z8+GL1NvnJqPMrUUy8o4c2n3utnSF7DV4D12IUwinbEt5bTILl13wJd/NeMvXGrqCXh5/21b+YeD0/zs/36In75wsejjfuOx0/ze3x/mtVcP87l3X+/I7uy1bO0PcM5MUsohFCvdmRNy9+7qwO8o0UQKl4DPU50fcftgsOKMfz4Sr6i+b7F26OfEbJgHj87ySy/eYtv87ddefgWb+wL85WPObE+y1i3my/h7A220ucVWxn9+yZDwrW3uQu0GubLbt0qUc4JR51fq8gbvQ6YNc77AD0a5x07gX53Yta/ogdXA78T07mw4jtftKloK+8+v28X/ueNnWIwmedufPcLv/t0zBRVP33riDP/1u8/wyl1DfP4XbyzLxNAOWyqUdIbipRu0wWqNP6xLPc4SiRs+PZVm04XYPtjB+eVYRXKsSqd2LXqDXoa7fBwxJZ1/8ehp2tzCL7x4k+3H8HpcvHhrHwfOLjlSOjl+Icxotz/vi0JEGLK5kMXK5vNl/FeNdtLmlqrr+a0afzkZv9WEXmtb8Mhxw0LZUpasZedIF6fmI8SS6weGQ1PLtLe5syZ4drECvxPTu3Mh4/fYzmvtddeM8M8ffxl33jLJXzx6mld/9t/5x2emL/md++5Pz/KJew9w+44BvvhLN+KtUvIGlUs6w7HS9u1aWJ8Soo3a3BWRTSLygIgcEZFDIvLRPNe8WUQOiMh+EdknIrflfC9t3r5fRL7v9A9QiKjDi9bXst1s8J6sIOu3/E2cYOdIF8+dDxGJp/j2vrO84drRrBOmXXZv6mEhkuDsxZWKz3NsJpw327cY6vIxY2OI6/zSpXYNufg8bq4e7ap+xl9BqWeo0xjIyp3gTWcUjzw/z0u29xcMlrtGOskoo5SzHoenlrlqtLPk2nc243dA2ZPPrmE9Onwefu/nruF7v3Yr/UEfH/rLp/jVrz/J1OIKf//0FB//1tPcsq2fL79n7yXzDdWgUklnOWsXAfweNyIQaWA5Zwr4uFLqKuBm4MMisra1/i/AHqXU9cD7gK/kfG9FKXW9+efnHDm1DSKJdFXq+xZZSWeZdX6lFPPhBAPrNMRK4aqRTo7NhPn2k2cJxVPc+ZLJkh9jj5mdHqhQG5/JKI4XCfzDnfZsG6aXYgS8broKvLj2bOrh4Nmlqi6jsQJ/qVptMD7dXDfedYlZ2+GpZZZWkty2zorE1Z3KhVUwmYzi8PRyyWUeyKnxO1HqCZVnNLhnUw/f/8itfPKNu3j4+Byv/uy/87G/2c/eLX185c7qB33IceksU9lTztpFMGTYgbb6beEqGviVUtNKqafMr0PAEWB8zTVhtfpZLQjUfSVUNF7djH9zfwCXlB/4Q/EUiXSGAccy/k4SqQyf++ejXDvexY2be8p6DK/bxYEKSyfnFldYSaYvs2rIxe707vTSCiPd/oKZ8Z6JHiKJtGNuqflYXjEaeOU2F68d7+bYTDhbtrHq+7ds7y94H8PK2rVunf+FhSjheMqWB/9afB43HT6PI9O7hl1DeQmMx+3igy/dzj/95ku59YoBbr1igHt+5UVVGbzMh4iwtQJlT7nNXbD27jZo4M9FRCaBG4DH8nzvrSLyLPAPGFm/hd8s/zwqIm9Z57E/aF63b3Z2tpRj5SWSSFVFw2/h87jZ3Bcou8HrlIbfwlrKcjGa5D23TJbV2/B53Owa7ax4KCqr6Bler9TjZzmWYqXIR11rAUshrAZvNfX8pRq0reXa8W7SGZXVsD98fI6dw53rluLcLmHHcAfPraPlL8WDPx+9wbaKh7gyGcV8JL9dQyls6gvw5ffs5evvu6nsQFouW/orCPzxVFmlHqivJ7/twC8iHcB3gI8ppS77/KmU+q5SahfwFuAPc761WSm1F/hF4HMisj3f4yul7lJK7VVK7R0cXH9ZtB2iiXS2c14tKpF0zjkwtZvL9qGg6brYxs/tGSv7cXZPdPPMueWKfIiswJ9vatfC7kKW80sxRroKm3JtGwjS6fNUtc6/tFKaF/9ashbN55aIJdM8cWqBl1xRONu32Dncta6W/9DUEh7zDaIc+oK+igP/RXMIrBK/qXpTrqQznkqTSGXKUntBfReu2wr8ItKGEfS/oZS6d71rlVIPAttFZMD8+5T53xPAv2F8Yqg6xqL16mYO2weNqb9y6stZu4Yy1y6uxedx87YbxvnYq3ZUVBvdPdFDOJ6qaKH8sZkQAx2+dRfIr+7eLdzgTZnDW+tl/C6XsHtTd1WtG5bN7VvlMtbtpy/o5Zlzyzx1+iLxVOYym4Z87BrpZDYULxicD00ts2O4s2zvmv5g5bYN1srFSjP+elKupDMcK2/7lkU9F67bUfUIcDdwRCn12QLXXGFeh4jcCHiBeRHpFRGfefsAcCvg3HjoOlS7xg9Gxh9PZbI+4aVQjRfMH79zD++9dWtFj7FnwiidVFLnPzYTzju4lYudIa65sJFNjhZZtXf9ph6enQ4VlT6Wy3KsslKPiHDNmDHB+/Dzc7hdwk1b+4reb70Gr1KKQ1NLJU/s5tLnQOC3hrc2csZvSTpLbfCGy1y7aGHs3W3cUs+twB3AK3NkmW8UkQ+JyIfMa94OPCMi+4EvAO8ym71XAftE5GngAeDTSqmaBP5IIl31wG8pe46XUe6xavy9NjYm1ZIrhjoIeN1lK3uUUhy/sL6iBwyZI6wf+KeWLl3AUog9Ez2kMqqgJ06lVFrjB7huvJujF0L867OzXL+px9bQz3rbuGZCcebCiYoD/3wkUdHchhPW4vXGmoE4VeI2rnKdOS2CPk/dbJmLnlgp9RCwbqdQKfUZ4DN5bn8EuK7s01VANJEiUOUmkaXlPzEb4RU7S7vvfCROd3tbVYdTysHtEq4dK790cmE5TiieKlp3tn729RayZBewrFPjByPjB6PB+zNbeks8cXEqrfGDUedPmQ3e33jlFbbuM9jpozfQljfwlzuxm0tf0EsilTHKomW+VlZ9ejZu4O8NtJUl6SzXi98i6K3f+sXGijoOkUhlSKYVwSpn/H1BL93tbWU1eOfCcccUPU6ze6Kbw1PLJZlpWaxn1ZCLiBSVdK43tZvLUJef0W5/VRq8ybQRGJ3I+C0K2TSsRcSw3M7X4D1kDoRdNVpYMluMVb+e8ss9syHTrqGCHki9KVfSaWXrZTd3fQ3e3N1oRKu4djEXETE9e8oJ/ImG/Xh83UQ38VSm5L2vUHjdYj6MIa71Mv4VfB4XPYHiL6w9Ez1VafAuVzC1m8tEbzvd7W20t7m5YbP9TyW7RoylLGtVVoemlpnsD5TlE2PRF6h8enfW1PBXyxqlVkyWIem0fIbKrfF3mM3darvL5qMpA3+kiktY1mJIOktXwMxXMPRSbVYbvKXX+Y/NhOkJtNn62Ya7/FxYR845vRRjrKfdVlDZs6mH0/NRx9dIVmLXkIuI8MpdQ7z+2pGSyns7R7qIJtKX2WhYHvyV0NdRuUNnoZWLG43JMiSd2eZumZ92Al4PGQXxOixcb8rAH63i2sW1bB/sYDYUzxp52WU+knDMp8dptvQH6G5v4+C50jPo4xcMRY+dYD3U5Vt3C5eh4bfnN7RnU3U2clmBv9QlLPn403ddz5++6/qS7pNP2bO0kuTMwkrJVsxr6c+Wesr35C/XrqHRmBwoXdJZeXPXcuisfbmnKQN/LTP+3AavXZLpDIvRZMPW+EWE3RPdPH2mtIxfKcXRmRBX2CjzgJHxh+Opgr/4xaZ2c7luvBsRSj5zMZbNF3elGX+55NvGdbiMHbv56HXAk79Ug7ZGZUt/6ZLOUCyF1+0qe44i68lfhwZvUwb+WtX4wSj1QGn7d61mmlNTu9Vg90Q3z10oTRs/H0mwGE0WbexaWENc+eyZ0xnFheXLl6wXotPfxpVDnTx0vHK7j1ycKvWUS4fPw0Rv+yUNXicUPQCdPg9tbim7xp/OKLNk2bi/x3axJJ2lrGEMl+nMaVHPLVzNGfit7Vs1CPxb+gN4XMKJOfuBPyuBa9CMH4wJ3nSJ2njLQrjY8JbFcGfhFYzz4TipjCppgfg7907wxKmLHKzQXTSXbKmngiZqpexas5Tl8NQyQ52+ijNtEaEv6C27L3IxmiCjaNheVSn0Btro8ns4XYKWv1xnTotAdu+uDvyOYL2DtldZzgnGztrNfQGen7GfKawatDVuplTOBK81yGbXO2a9peuWlDPfrt1C/PyLNtHh83D3Qyds36cYy9kaf/0C/86RTk7MRYinjITm0NRyxWUei95A+dO7qxr+0vY+NCIiUvL+3UqcOWF1LWw9PPmbMvBHa1jjB6PcU0rGPx9x1qenGgx3GRllKcqe4xdCdPg8thuyQ5ZRW56M366GP5cufxvvetEmfnBgmumlypfJgBH4fR5XTbzhC7FzpIt0RvH8jLGR6/hsuOIyj0V/h7fsUs+qXUPj/h6XQqkuncbaxcpLPfXYwtWUgT9SQ1UPGA3eU3NR22Ztc6HGz/hFhD0TpU3wWlu37Gq6O30e2tvceYe4ztu0a1jLe18ySUYpvvaIM7uDnZjarZSsdcOFZZ47HyKdUWV58OejL+gru9STtWtoguYuGLMW55ditp1pjYy//N8NqxStVT0OYWX81fbqsdg+2EEineGsTSnYXGRjTDvunujhxGyk4ELsXObCcfadvpjd4mWH7PRuHtuG6aUYXrcrO11ql019Ad5w7Sh/9dhpR2qnTvj0VMrWgSBtbuHZ86GKPfjX0h8sP+O3EphmUPWA4aKaTKvsG1oxwvFkhRm/qerRpR5niCRSeD0u2srcmFQq24cMRYBd6wZryXqjTzvuNoP4wXPFyz1/8ZPTJFIZ7rhlsqR/Y6gr/wrG6aXYupu31uP9t29lOZbi20+eLfm+a6nUmdMJ2twutg928Nz5EIemlujyG0ofJ+gNeAnFUiV70YMxtev1uMpaNt6IjPUYz+k5m267lTd3tarHUaLxdNV9enLZNmBJOu3VB+cb2Kcnl902J3hjyTR/8ehpXrVryLaU02K4y59Xznl+yb6Ucy03bu7lxs093PPwyYp38TZCxg+ryp5DU8tcPdblWNJgTe8ulrGCcS4UZ7DD1/AJjF2swD+1WHwlqFKq4uauz+PC7RKt6nGKSCJVs/o+GIMwfUGv7QbvXLhxp3Zz6Qt62dTXXlTZc+9T51iIJPjA7dtK/jeGO31cWI5f5lcyvbxScn0/lw/cvo3T81H++ciFsh8DzBp/A5Tkdo50Mb0U4/BUecvVC2EJDMop98yG401T34fcwF8844+nMqQyqiIdv4gQ9Lrrsn6xKQP/SiJdM0WPxbaBYNNl/GBk/etNw2Yyiq/8+ATXjndx87biy0XWMtzlZyWZJpST9WQyigtLcUZLkHKu5bVXDzPR287dPz5Z9mOAsWi9UTJ+gEQ645iUE1b3QZQj6ZwNxRt6FqVUuvweOnye7B6I9Vi1a6jsd6NeC9ebMvAbS1hqm6VttynpVEoxF0kw2MCKnlz2THRzbnEluypyLf/67Awn5iL86u3byvrIn9Xy50g65yMJEulMRRm/x+3iV27dyuOnFsq2a85kVEPU+GHVugGca+wC2QSknIy/WQzaLESE0W6/rYzfEjxU2t+o18L1pgz8tVi7uJZtg0HmwgmWousrYMJxo5G2UTL+68bNOn+BBu+Xf3yC0W4/b7xutKzHH+q0tPyrddXsApYKAj/Az++doNPn4e6Hysv6Q/EUStV3eMtitNtPp9+Dz+PK+kM5gaWaKlXSmc4oFiLNYdeQy1hPu60avyXBrKS5C8b6Rd3cdYh6ZfwAzxfJ+q1duxuhxg+GN78IHMhT7jl4donHTi7wvlu3lq2gyi5dz5nenS5Tw7+WTn8b775pE/9wcLqsvciNMLVrISJcN97NdePdeBxUq/WYP1upGf9CxLJr2Bi/x3YxAr/9Uk8lzV0wZo20SZtDRBOpmtf4tw/ZM2uzSiYbJePv8HnYPtiRt8H75R+foMPn4V03bSr78Ye6LvfrOb/sTMYPcOdLJgH42iOnSr5vvQ3a1vK5d13P53/xRkcf0+M2Ft2U6tDZDCsX8zHe42c+kihqTljp2kWLeu3dbcrAH4nXPuPf1NtOm1susc/Nh5Xxb6RMafdEN0+fXbpEeXNucYV/ODjNu1+0qSIDsw6f0VDL1fJPL8VocwsDDnwqmugN8IZrR/irx18o+QXm1PYtpxjq8jvyZrgWw6itNE/+VbuGjfN7bAdLUGBZhhSi0rWLFkGfWzd3nSKaSNVUxw9G5nTL9gG+t38qa6aVD8unZyO9YPZM9DAXjl/yYvhzs27+K7dtrfjx1y5kOb8UY7jLj8vljD78A7dvIxRL8bf7zpR0v0Zw5qwFxvSuzvjBvqSz0rWLFgGvh7Au9VROJqOIJtIE6jBN+P7btjIbivODp6cLXmM5c5ZqRVBPrAleq9yzHEvyzSfO8MbrRhnvqXyC1Ni9u/qmMrVYmYZ/Lddv6mHvlt6SB7qsrWrdNnb+bmTKcejM+vRskJKlXcZtTu+GHSr1dDRqxi8im0TkARE5IiKHROSjea55s4gcEJH9IrJPRG7L+d6dInLM/HOn0z/AWlaSlhd/7d0UX7pjgB1DHdz90MmCC5TnwnG6/J6S9q7Wm6tGu/C4hKfNCd6/efwM4XiKX7298mwfMP16clQ9y7GS7Jjt8IHbt3JmYYX7D5+3fZ9Gq/FXi/4Ob8nrF2dDcXweV8UZb6Mx3O1DBKaLKHvC8RT+tsptYQJeD9FE2rYxnFPYOXUK+LhS6irgZuDDInL1mmv+BdijlLoeeB/wFQAR6QM+BbwYuAn4lIj0OnX4fGQN2urwCykivP+2rRyeXuYnJ+bzXjMfTmyoMg+Av83NzpFODp5dIpnO8OcPn+TFW/uylg6VMtTlZ8ac3lVKlbRy0S6vuXqE8Z52vv3kOdv3WVpJ4nZJXZKIWtIX9BpLVUoIPpaGv1nsGix8HjcDHb6ipZ7lCp05LbLWzCVsunOCooFfKTWtlHrK/DoEHAHG11wTVqspbhCwvn4dcL9SakEpdRG4H3i9U4fPh/WxqV4v1rfcME5/0FtwYnRug66q2z3Rw4Gzi9x3cJqppRi/WoY9QyGGOn3EUxmWV1JcjCZJpDK2Pf3t4nYJ14x18cKCfb/15ZUUXX5P0wW3tfQGvKTNYTW7bNTfYzuM9bQXnd4Nx1OOWHlkHTprrOwp6XOKiEwCNwCP5fneW0XkWeAfMLJ+MN4gcjtqZ1nzppFz/w+aZaJ9s7Pl7021puBqPcBl4W9z88s3b+Ffnp3hRB63zvlIYsNIOXPZM9HNcizFp3/4LNsGg7xy15Bjjz1sSTpDsayGf6zHefXKRG+AsxdXCpbh1tIoBm3Vxvp9LKXOPxtq3sA/3uMvWuMPxSrbt2thefLXeguX7cAvIh3Ad4CPKaUuW8SqlPquUmoX8BbgD6275XmovK86pdRdSqm9Sqm9g4ODdo91GbVctF6IX755C16Pi3sevjzrn9tAPj25WGWd6aUY779tq2OKG8gJ/MuxbG3V6Ro/wHhvO9FEmsUi09UWrRL4+0zZbCmBfy4cbzpFj8VYdzvTi7F1E4Rwhc6cFllr5kbM+EWkDSPof0Mpde961yqlHgS2i8gARoafO90zAUyVeVZbRGq8djEfg50+3nL9GN9+8uwlo/DJdIbFaHLDTO3mcuVwB/42YzHK22+ccPSxs9O7y3Gml0tfuWgXy8Pert96I2zfqgV9gdL8elLpDPORRFMZtOUy2tPOSnL9BCFc4dpFC+vNo+ECvxgFzruBI0qpzxa45grzOkTkRsALzAM/Al4rIr1mU/e15m1VI1rjtYuFeP9t24glM/zV4y9kb7PeBDaila3H7eIjr7iC333T1Y7vn7X8ei4sxzi/tILbJVUpI1hSPbub0pZjLRL4Syz1LEQTKNV8Gn6LcbPMuF6CUOnaRYtAnbZw2YmOtwJ3AAdFZL952yeBzQBKqS8BbwfeIyJJYAV4l9nsXRCRPwSeMO/3B0qpBSd/gLVkM/46B/6dI53cvmOArz1yil+9fRtej2t1ancDafhz+cgrd1Tlcdu9brr8HmaWY4TiKYY7fbgdLCVZWBn/2Yv2Mv7lVin1lGjNbK1cbNYaf+4Q17Xj+Z1QQ7HK1i5aWCKUWts2FD25Uuoh8tfqc6/5DPCZAt+7B7inrNOVQbbGX8dSj8UHbt/Gnfc8zg8OTPG2Gyey05GNvGS9Xgx3+bmwHGc5lmTUgaGwfHS3t9Hh89gq9SilzCUszR/4271u2tvctgP/bJMtWV9LseldpZRjpZ7VvbsNVurZaFiqnnpn/HD5QNfcBjNoqyXDXX5mQrGKVi4WQ0QY72m3lfHHkhmSadUSGT8YWn77Gb9p19CkCUx/0IvX4yro1xNNpMmoyu0aIEfVU2PbhqYL/CuJFCLgb6v/j2YNdB2aWubREwtZuwYnzMeajSFzBePU0gqjDmv4cxnvbeecjcDfKlO7Fsb0rs3A3+QZv4gw1l1Y0rnqxe9Ejb+BVT0biUgiTaDN3TBDN9mBrodOMBdO0OYWutrr/2mk0Rjq8jO1tEIsmalaxg9Gnd9Oczdr0NYi/69KyfhnQ3H8ba6mnmhez5c/a9DmQKmnze3C63E1ro5/oxBNpOpi11AIf5ubXzIHuvadWqA/2Hxj7k4w3OXDkk1Xsmu3GOM97SzHUtkXbyFaLePvK8GozdLwN/Pv8XqbuLL7dh2KM0Fv7Y3ami7wR+LphstE7rh5C20uF/tOX9T1/QIM55R3qpnxj9vU8jeaF3+1KanGvwH9pkplrNvoOSXTmcu+59TaRYt6LGNpusAfTaTqruFfy2Cnj7fcMAZoRU8hrCEuqI5dg8VEbwCAswvrB/6Wy/g7vKwk06zYKDnMhuJN29i1GOtpJ6O4xC7cwqntWxbBOqxfbLrAH4mn6zq1W4j332aYmm1UDX+1sYa4XFJdtYhdv/VWWcJisTq9W3why1w43rSNXYtVSeflgT/s0L5di4Cv9gvXGys1doBoIkVPoPGC686RTv7bf7jKMSvjZmPIzPiHOv2OLhNfy0CHF5/HVbzUE2ucReu1wFoMdDGSZGId4/RUOsNCtAVKPeto+UMOqnrAeAOptaqn6QJ/JJFmvLfxMn4wBro0+fF53PQG2qpa3wdTy29D2bO0kqTT56nKBHEjYvWeimX8C5HmtmuwsMqN+eyZnVq7aBHwurM7jGtF0wX+aLzxavwae1w53Mm2wWDV/53xnuJa/lYxaLPotWnbYE3tNqtBm0XA66En0JY34w/HjJ3eTiUFQW/tm7tNFyGjycZT9Wjs8dVfuQlXDbpOE73t3D99mbP4JSy3WODvt2nNbGWmzV7qAcOeOV+NPxRLOdbYBUPVU2uTtqZr7kbjadp1xr8hafe68Xmq/6Y90RtgLpxYV8GyvJKiu0WGt8AYVPO4pGjgt4wGm73UA4WHuMJxZ7z4LQI+t57crYREKkMindEZv2Zd7Ch7WmUJi4WI0GtDy5+1a2iFjL/HX7C561RjF4xSTzyVIZVnZqBaNFXgX6njonXNxmHVnrlwg7dVnDlz6Qt4iy5jmQ3FCXjdWVfJZmaswJS3U5bMFtZzWUvbhqYK/JE6L1rXbAzsTO8ux1or4wdD0nlmIUomU3jlYDMvWV+LJelc69Lp1NpFCyte1dK2oakC/6oXf/NnI5ryGer043FJQWVPMp0hmki3XOD/2T1jPHs+xNd+cqrgNUbgb25Fj0WhTVxOefFbBOqwfrGpAv+qF7/O+DWFcbuEsXV8+VedOVsr8P/CTZt41a4h/t8fPsuz5/OrnmZDzbtkfS2WWeD0GmWPU2sXLTqy1sy61FMWVqlH6/g1xRjvaS9Y6mk1nx4LEUsolOUAAA2pSURBVOEz79hNl9/Dx765n1jy8kDUCgZtFkPmCtDcBm8m49z2LQsrXtXStqGpAr9ldNSIXj2axmK9hSyt5syZy0CHjz9+5x6ePR/if/zjc5d8L5nOsBBpncDvcbsY6bpU2WMFZ0ebu3XYwtVcgd/MUHTGrynGRG87F0IxEqnLJXSttoRlLa/YOcR7XzLJPQ+f5MGjs9nbLalnq5R6wJB05n4yDDls0Aariapu7pZJNG6VenTGr1mf8Z52lILpPF4srVrqyeW337CLK4c7+PjfPp0N+K00tWsx1tN+iarHybWLFlk5p874y8PSwTbConVNY5OVdOYp9yybWV2rNXdz8be5+V/vvoGlaJJPfOcASqlVn54WyvhHu9uZXlrJSlydXLtoEWxEVY+IbBKRB0TkiIgcEpGP5rnml0TkgPnnERHZk/O9UyJyUET2i8g+p3+AXKyMv11n/JoibLIWsuQL/C3mxV+Iq0a7+C+v38n9hy/w14+fYS5kGbS1TuAf7/GTTKvsxHI1Sj3tbaaqp4alHjunTwEfV0o9JSKdwJMicr9S6nDONSeBlymlLorIG4C7gBfnfP8VSqk5546dn0gijddcXqzRrMdItx+XwNk8yp6llSQ+jwt/m04g3nfrVv796Cx/+IPDvGn3KAADna2h44fVIa5ziysMdfmzpZ4uBzN+t0tob3PX1KitaIRUSk0rpZ4yvw4BR4DxNdc8opS6aP71UWDC6YPawVi0rl+smuK0uV0Md/nz2jYsRVtvarcQLpfwJ+/cg7/Nxd8+eZag191S4om107tOr120qPXe3ZJSYxGZBG4AHlvnsvcDP8z5uwL+SUSeFJEPlnrAUjAWrbfOL6WmMiYKSDpb0a5hPYa7/Hz67bsBmn7l4lrGui/dxGWtXXSyuQuGsidaw8BvO0qKSAfwHeBjSqm8Y30i8gqMwH9bzs23KqWmRGQIuF9EnlVKPZjnvh8EPgiwefPmEn6EVYxF6zrj19hjvKedfacvXnZ7qy1hscPrrhnhI6+4gtQ6Pj7NSFe7h6DXnZV0huIpRCDgcBkw4PUQbjRVj4i0YQT9byil7i1wzW7gK8CblVLz1u1KqSnzvzPAd4Gb8t1fKXWXUmqvUmrv4OBgaT+FSSSR1j49GttM9AaYXopdZofbapbMdvm/XreT337Drnofo6aIyCW+/KFYkg6vB5fDKzk7fO7G0vGLiAB3A0eUUp8tcM1m4F7gDqXU0Zzbg2ZDGBEJAq8FnnHi4PlYSaS0T4/GNuO97aQzigtr9p3qUo8ml1wtfzjmrF2DRcDrqakts52f4FbgDuCgiOw3b/sksBlAKfUl4HeBfuCLxvsEKaXUXmAY+K55mwf4K6XUPzr6E+QQiacZ69EvWI09sgtZLq5kvwbd3NVcyliPn0NTS4Dzaxctgj73ujbhTlP0J1BKPQSs+7lGKfUB4AN5bj8B7Ln8HtXBqPHrUo/GHrkLWW7a2gcYJlyheMpRuZ5mYzPW3c5cOEEsmXZ87aJF0OupaXO3qQTvkURaG7RpbDPWc/n0biiWQqnWntrVXEqupNPptYsWQV9tSz1NFfijcZ3xa+zjb3Mz0OG75CP2ckz79GguJRv4F1eM5m5VavzGwnWlaqOaaqoo+R9ftp09m3rqfQzNBmKi99KFLK26hEVTmLGcTVzhWHXKgEGfh1RGkUhn8HmqX7VoqsD/G6/aUe8jaDYY473tHJ5aHUvRzpyatYx0G4F/ajFWxRq/ac0cT9ck8DdVqUejKZUJcxOX5b7YyktYNPnxedwMdvo4czFKNJF2dO2ihTV/VCvbBh34NS3NRG87iVQm676oM35NPsZ62jl2IQQ4u33LwvoUUSujNh34NS2N5ctvuXTqGr8mH2Pdfo5eCAPOG7TB6vKoWlkz68CvaWnGey715V9aSeJ2iZ4A11zCWE87K+Zq184q1Pg7aryMRQd+TUuzdhOXZddgTptrNMCqpBOcd+aE1T3htVq/qAO/pqXp8HnoCbRxbtHw5V9a0VO7mssZNyWdUJ1ST60XruvAr2l5crX82plTk4/R7tyMvzo6ftClHo2mZoz3rC5kWdZe/Jo8XFLqqZJXD1Az2wYd+DUtz3hPgHOLKyildODX5KU/6M3u8q5Gqcff5sIl1MyoTQd+Tcsz0dtONJHmYjSpSz2avLhcwli3P7sY3WlEhGANt3DpwK9peXKVPXoJi6YQo93tdPg8VVN8BWq4hUvLFzQtj7WE5dhMiGRa6cCvycuu0c6se2s1MDJ+Hfg1mpqwqdcY4rLM2rqqoNPWbHw+8fpdJNbsZ3aSoM9TM8sGHfg1LU9Xu4cOn4dDZuDXGb8mH/42N/4q1PctLE/+WqBr/JqWR0QY72nn8LQO/Jr6YWzh0oFfo6kZE73tOQZt+oOwpvYEfR6iWtWj0dQOS9kDOuPX1Ieg112zjF+nNhoNq8oe0IFfUx/eeN0o14x11eTfKprxi8gmEXlARI6IyCER+Wiea35JRA6Yfx4RkT0533u9iDwnIsdF5Led/gE0GieYMJU9UB33RY2mGC+9cpA7bpmsyb9lJ+NPAR9XSj0lIp3AkyJyv1LqcM41J4GXKaUuisgbgLuAF4uIG/gC8BrgLPCEiHx/zX01mrpjlXo6fR7cLm3JrGluimb8SqlppdRT5tch4AgwvuaaR5RSF82/PgpMmF/fBBxXSp1QSiWAbwJvdurwGo1TTJiBX/v0aFqBkpq7IjIJ3AA8ts5l7wd+aH49DpzJ+d5Z1rxpaDSNQH/Qi7/Npev7mpbAdnNXRDqA7wAfU0otF7jmFRiB/zbrpjyXqQL3/SDwQYDNmzfbPZZG4wgiwlhPu5ZyaloCW7/lItKGEfS/oZS6t8A1u4GvAG9QSs2bN58FNuVcNgFM5bu/UuoujN4Ae/fuzfvmoNFUk996zZVVcV7UaBqNooFfDCu6u4EjSqnPFrhmM3AvcIdS6mjOt54AdojIVuAc8G7gFys+tUZTBd60e6zeR9BoaoKdjP9W4A7goIjsN2/7JLAZQCn1JeB3gX7gi6ZlaUoptVcplRKRjwA/AtzAPUqpQw7/DBqNRqMpgaKBXyn1EPlr9bnXfAD4QIHv3QfcV9bpNBqNRuM42rJBo9FoWgwd+DUajabF0IFfo9FoWgwd+DUajabF0IFfo9FoWgwd+DUajabFEKUab0hWRGaB02XefQCYc/A4TqPPVxn6fJWhz1cZjXy+LUqpQTsXNmTgrwQR2aeU2lvvcxRCn68y9PkqQ5+vMhr9fHbRpR6NRqNpMXTg12g0mhajGQP/XfU+QBH0+SpDn68y9Pkqo9HPZ4umq/FrNBqNZn2aMePXaDQazTo0TeAXkdeLyHMiclxEfrve51mLiJwSkYMisl9E9tX7PAAico+IzIjIMzm39YnI/SJyzPxvb4Od7/dE5Jz5PO4XkTfW6WybROQBETkiIodE5KPm7Q3x/K1zvoZ4/syz+EXkcRF52jzj75u3bxWRx8zn8G9ExNtg5/uqiJzMeQ6vr8f5KqEpSj0i4gaOAq/B2Pr1BPALSqnDdT1YDiJyCtirlGoYDbCIvBQIA19XSl1r3vY/gAWl1KfNN9BepdQnGuh8vweElVJ/Uo8z5ZxtFBhVSj0lIp3Ak8BbgPfSAM/fOuf7eRrg+YPskqegUipsbvl7CPgo8FvAvUqpb4rIl4CnlVJ/1kDn+xDwA6XUt2t9Jqdoloz/JuC4UuqEUioBfBN4c53P1PAopR4EFtbc/Gbga+bXX8MIFnWhwPkaAqXUtFLqKfPrEHAEGKdBnr91ztcwKIOw+dc2848CXglYQbWez2Gh8214miXwjwNncv5+lgb7Jcf4hfknEXnSXCzfqAwrpabBCB7AUJ3Pk4+PiMgBsxRUt1KUhYhMAjcAj9GAz9+a80EDPX8i4jY3+80A9wPPA4tKqZR5SV1fy2vPp5SynsM/Mp/DPxURX73OVy7NEvjzbQhrtHfmW5VSNwJvAD5sljE0pfNnwHbgemAa+J/1PIyIdADfAT6mlFqu51nyked8DfX8KaXSSqnrgQmMT+5X5bustqfK+YfXnE9ErgV+B9gFvAjoA+pSCq2EZgn8Z4FNOX+fAKbqdJa8KKWmzP/OAN/F+CVvRC6Y9WGrTjxT5/NcglLqgvlizABfpo7Po1n3/Q7wDaXUvebNDfP85TtfIz1/uSilFoF/A24GekTEWgvbEK/lnPO93iyjKaVUHPhzGuQ5LIVmCfxPADtMNYAXeDfw/TqfKYuIBM0GGyISBF4LPLP+verG94E7za/vBP6ujme5DCuomryVOj2PZuPvbuCIUuqzOd9qiOev0Pka5fkzzzIoIj3m1+3AqzF6EQ8A7zAvq+dzmO98z+a8sQtG/6FRX8sFaQpVD4ApS/sc4AbuUUr9UZ2PlEVEtmFk+WAsuP+rRjifiPw18HIMx8ELwKeA7wHfAjYDLwDvVErVpcFa4HwvxyhTKOAU8B+tmnqNz3Yb8GPgIJAxb/4kRh297s/fOuf7BRrg+TPPuBujeevGSEK/pZT6A/P18k2MMspPgV82s+tGOd+/AoMYJeb9wIdymsAbgqYJ/BqNRqOxR7OUejQajUZjEx34NRqNpsXQgV+j0WhaDB34NRqNpsXQgV+j0WhaDB34NRqNpsXQgV+j0WhaDB34NRqNpsX4/wFS36ICCWBZ3QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.09082535  0.17446782  0.16507269  0.00792867 -0.06083119 -0.16273234\n",
      "  0.03887882 -0.10283275 -0.17272954  0.02195246]\n",
      "2.806044517503409\n"
     ]
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.show()\n",
    "print(bias)\n",
    "diff_thetas = thetas - init_thetas\n",
    "print(np.sqrt(np.sum(diff_thetas*diff_thetas)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.72482535  0.12482535 -0.15117465  0.72682535]\n",
      "[-0.62953218 -0.38753218 -0.29553218 -0.54553218]\n",
      "[0.60307269 0.28107269 0.07107269 0.60707269]\n",
      "[ 0.23992867  0.39192867 -0.90007133  0.07192867]\n",
      "[-0.25083119  0.52916881  0.57316881 -0.24883119]\n",
      "[-0.26873234  0.23926766 -0.49873234 -0.32273234]\n",
      "[-0.61912118  0.19887882  0.65087882 -0.19912118]\n",
      "[ 0.80316725  0.38516725 -0.73483275  0.82916725]\n",
      "[ 0.29127046 -0.37272954 -0.29072954  0.34527046]\n",
      "[-0.38604754  0.41395246  0.12195246  0.13995246]\n"
     ]
    }
   ],
   "source": [
    "#Check for favoritism\n",
    "for i in range(NUM_CLASSES):\n",
    "    print(circuit_tighten(np.random.randn(ENCODING_SIZE), MASK, thetas[i]) + bias[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overfit a linear model with same number of parameters:\n",
    "etas = [1e-2]\n",
    "start = time.time()\n",
    "recoder = nn.Sequential(nn.Linear(10, 40), nn.ReLU(), nn.Linear(40, 10))\n",
    "for eta in etas:\n",
    "    for epoch in range(4):\n",
    "        for i, data in overfit:\n",
    "            inputs, labels = data\n",
    "            X = encoder(inputs.view(len(labels), -1))\n",
    "            \n",
    "            dcost = qml.grad(cost, argnum=[2,3])\n",
    "            theta_grad, bias_grad = dcost(X.numpy(), labels.numpy(), thetas, bias)\n",
    "            loss = cost(X.numpy(), labels.numpy(), thetas, bias)\n",
    "            losses.append(loss)\n",
    "            thetas -= eta * theta_grad\n",
    "            bias -= eta * bias_grad\n",
    "            acc = accuracy(thetas, bias)\n",
    "            accuracies.append(acc)\n",
    "            print(\"%d batches took %f seconds and has accuracy %f, with train loss %f\" % (i + 1, time.time() - start, acc, loss))\n",
    "            if i == 1:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
