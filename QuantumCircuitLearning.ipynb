{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from MNISTData import MNISTData\n",
    "from AutoEncoder import AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODING_SIZE = 10\n",
    "NUM_QUBITS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device('default.qubit', wires=NUM_QUBITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pennylane.ops import RX, RY, CNOT\n",
    "\n",
    "# x will be a length ENCODING_SIZE vector that represents\n",
    "# the encoding of a MNIST image\n",
    "# thetas is of size 2 * NUM_QUBITS\n",
    "@qml.qnode(dev)\n",
    "def circuit(x, thetas):\n",
    "    for i in range(ENCODING_SIZE):\n",
    "        RX(x[i], wires=i)\n",
    "    for i in range(NUM_QUBITS - 1):\n",
    "        CNOT(wires=[i, i+1])\n",
    "    for i in range(NUM_QUBITS):\n",
    "        RX(thetas[i], wires=i)\n",
    "    for i in range(NUM_QUBITS, 2 * NUM_QUBITS):\n",
    "        RY(thetas[i], wires=(i - NUM_QUBITS))\n",
    "    return tuple(qml.expval.PauliZ(wires=i) for i in range(NUM_QUBITS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.80901699 0.6545085  0.5295085  0.42838137 0.34656781 0.28037925\n",
      " 0.22683158 0.1835106  0.14846319 0.12010925]\n"
     ]
    }
   ],
   "source": [
    "# example input\n",
    "print(circuit([np.pi/5]*(ENCODING_SIZE), [np.pi]*(2 * NUM_QUBITS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(X, actual_labels, thetas):\n",
    "    b = X.shape[0]\n",
    "    yhats = []\n",
    "    for i in range(b):\n",
    "        yhat = circuit(X[i], thetas)\n",
    "        yhats.append(yhat)\n",
    "    st = np.stack(yhats)\n",
    "    actual_class_vals = st[range(b), actual_labels]\n",
    "    shifted = st - np.max(st, axis=1)[:, np.newaxis]\n",
    "    the_sum = np.log(np.sum(np.exp(shifted), axis=1))\n",
    "    return np.mean(-actual_class_vals + the_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have to get our (encoded) images so that we may actually start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = MNISTData(batch_size=4)\n",
    "train_loader = data.get_train_loader()\n",
    "test_loader = data.get_test_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_from_stem = \"./autoencoder_models/1558731906/\"\n",
    "load_model_from = os.path.join(load_from_stem, \"ae.pt\")\n",
    "load_layers_from = os.path.join(load_from_stem, \"layer_sizes.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(load_layers_from, 'rb') as f:\n",
    "    layer_sizes = pickle.load(f)\n",
    "layer_sizes = layer_sizes[1:]\n",
    "ae = AutoEncoder(layer_sizes)\n",
    "ae.load_state_dict(torch.load(load_model_from))\n",
    "encoder = ae.encoder\n",
    "for child in encoder.children():\n",
    "    for param in child.parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                  [-1, 256]         200,960\n",
      "              ReLU-2                  [-1, 256]               0\n",
      "            Linear-3                   [-1, 64]          16,448\n",
      "              ReLU-4                   [-1, 64]               0\n",
      "            Linear-5                   [-1, 10]             650\n",
      "              ReLU-6                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 218,058\n",
      "Trainable params: 0\n",
      "Non-trainable params: 218,058\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.83\n",
      "Estimated Total Size (MB): 0.84\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(encoder, input_size=(28 * 28,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.96619343 -0.14789545  0.36387268  0.92188894 -0.85160081  0.85258638\n",
      " -0.28277243 -0.46211122 -0.81660402 -0.12947143 -0.8954551   0.56925904\n",
      " -0.6602414   0.76241819  0.59891522  0.99119002  0.85932832  0.62668308\n",
      " -0.53348369 -0.63579895]\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "thetas = 2 * np.random.rand(2 * NUM_QUBITS) - 1\n",
    "print(thetas)\n",
    "print(thetas.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 28, 28])\n",
      "4\n",
      "tensor([[44.7678, 24.3530,  0.0000, 13.3956, 32.0997,  8.4641,  9.2724, 16.5090,\n",
      "         28.4740,  0.0000]])\n",
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "# this is the transformation that you need to do in order\n",
    "# to pass it to the encoder. it is (1, -1) since the first number\n",
    "# is the batch size, which in our case is 1\n",
    "enums = enumerate(train_loader, 0)\n",
    "i, data = next(enums)\n",
    "inputs, labels = data\n",
    "print(inputs.size())\n",
    "print(len(labels))\n",
    "print(encoder(inputs[0].view(1, -1)))\n",
    "print(encoder(inputs[0].view(1, -1)).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 10])\n",
      "torch.Size([4])\n",
      "199.52496814727783\n"
     ]
    }
   ],
   "source": [
    "X = encoder(inputs.view(len(labels), -1))\n",
    "print(X.size())\n",
    "print(labels.size())\n",
    "start = time.time()\n",
    "qml.grad(cost, argnum=2)(X.numpy(), labels.numpy(), thetas)\n",
    "print(time.time() - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (CS269Q)",
   "language": "python",
   "name": "cs269q"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
