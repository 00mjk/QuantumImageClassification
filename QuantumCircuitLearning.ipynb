{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MNISTData import MNISTData\n",
    "from AutoEncoder import AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODING_SIZE = 16\n",
    "NUM_QUBITS = ENCODING_SIZE // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device('default.qubit', wires=NUM_QUBITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pennylane.ops import RX, RY, CNOT\n",
    "\n",
    "# x will be a length 16 vector that represents\n",
    "# the encoding of a MNIST image\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def circuit(x, thetas):\n",
    "    for i in range(NUM_QUBITS):\n",
    "        RX(x[i], wires=i)\n",
    "    for i in range(NUM_QUBITS, ENCODING_SIZE):\n",
    "        RY(x[i], wires=(i - NUM_QUBITS))\n",
    "    for i in range(NUM_QUBITS - 1):\n",
    "        CNOT(wires=[i, i+1])\n",
    "    for i in range(NUM_QUBITS):\n",
    "        RX(thetas[i], wires=i)\n",
    "    for i in range(NUM_QUBITS, ENCODING_SIZE):\n",
    "        RY(thetas[i], wires=(i - NUM_QUBITS))\n",
    "    return tuple(qml.expval.PauliZ(wires=i) for i in range(NUM_QUBITS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6545, 0.4284, 0.2804, 0.1835, 0.1201, 0.0786, 0.0515, 0.0337],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# example input\n",
    "print(circuit([np.pi/5]*16, [np.pi]*16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "def cost(x, thetas, W, actual_labels):\n",
    "    y = circuit(x, thetas)\n",
    "    class_predicts = torch.mm(W, y)\n",
    "    return loss(class_predicts, actual_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have to get our (encoded) images so that we may actually start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = MNISTData()\n",
    "train_loader = data.get_train_loader()\n",
    "test_loader = data.get_test_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_from = \"./autoencoder_models/1558553790/ae.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae = AutoEncoder()\n",
    "ae.load_state_dict(torch.load(load_from))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                  [-1, 256]         200,960\n",
      "              ReLU-2                  [-1, 256]               0\n",
      "            Linear-3                   [-1, 64]          16,448\n",
      "              ReLU-4                   [-1, 64]               0\n",
      "            Linear-5                   [-1, 16]           1,040\n",
      "              ReLU-6                   [-1, 16]               0\n",
      "            Linear-7                   [-1, 64]           1,088\n",
      "              ReLU-8                   [-1, 64]               0\n",
      "            Linear-9                  [-1, 256]          16,640\n",
      "             ReLU-10                  [-1, 256]               0\n",
      "           Linear-11                  [-1, 784]         201,488\n",
      "          Sigmoid-12                  [-1, 784]               0\n",
      "================================================================\n",
      "Total params: 437,664\n",
      "Trainable params: 437,664\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.02\n",
      "Params size (MB): 1.67\n",
      "Estimated Total Size (MB): 1.69\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(ae, input_size=(1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (CS269Q)",
   "language": "python",
   "name": "cs269q"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
